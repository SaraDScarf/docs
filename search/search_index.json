{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Welcome to Scarf's documentation, your one-stop guide for understanding and leveraging our platform's powerful tools to track usage metrics for your open-source software projects.</p>"},{"location":"#about","title":"About","text":"<p>Scarf provides open-source software maintainers with deep insights about their project's usage. With best-in-class open-source usage analytics and tracking capabilities, Scarf uncovers how and where your software is being utilized, which companies are relying on it, and much more. This data helps maintainers understand their project's reach, identify growth opportunities, and make informed strategic decisions. With its ethos firmly rooted in the open-source community, Scarf is not just a platform but a partner in your software project's journey toward success.</p>"},{"location":"#documentation-sections-overview","title":"Documentation Sections Overview","text":"<ol> <li>Getting Started Checklist: Preview the high-level Scarf set up process.</li> <li>Quick Start: Jumpstart your journey with Scarf. A concise guide to get you up and running with our platform quickly.</li> <li>Scarf Gateway: Understand the nuances of Scarf's secure and powerful gateway.</li> <li>Organizations: Learn how to manage and collaborate with your teams within Scarf's platform.</li> <li>Packages: Delve into the specifics of working with various Scarf package types, such as Docker, Helm, npm, Python, and more.</li> <li>Scarf SDKs: Discover how our Software Development Kits (SDKs) can accelerate your development process.</li> <li>Custom Telemetry: Track any custom behaviors by sending event data to Scarf from your code. </li> <li>Documentation Insights (Pixels): Uncover insights about your product's usage and onboarding through Scarf's cookie-free pixel tracking.</li> <li>Open Source Qualified Leads (OQLs): Identify organizations and individuals that have engaged with your OSS.</li> <li>Open Source Adoption Funnel Stages: Understand the level of engagement of potential leads.</li> <li>Data Export: Export your data for customized analysis. Explore the potential of data manipulation to suit your needs.</li> <li>Event Import: Import your data</li> <li>User Guide &amp; Best Practices: Make a plan to use the data uncovered in your OQLs.</li> <li>Troubleshooting: Find solutions to common issues and questions.</li> <li>API Docs: Understand the capabilities of a specific API version and its available endpoints.</li> </ol>"},{"location":"#contribution","title":"Contribution","text":"<p>Our documentation is an open-source resource hosted on GitHub. We welcome and appreciate your contributions to make it even better.</p> <p>For engaging discussions, interactive Q&amp;A sessions, and to meet our dynamic community of staff, open-source maintainers, and end-users, join the Scarf-Community workspace on Slack.</p> <p>Stay updated with Scarf's system status and uptime on our status page here.</p>"},{"location":"#welcome-aboard-and-happy-exploring","title":"Welcome aboard, and happy exploring!","text":""},{"location":"api-v2/","title":"API V2","text":"SwaggerUIBundle({       url: 'api-v2-public.json',       dom_id: '#swagger-ui-1',     })"},{"location":"custom-telemetry/","title":"Custom telemetry","text":""},{"location":"custom-telemetry/#custom-telemetry-with-scarfs-http-api","title":"Custom Telemetry With Scarf\u2019s HTTP API","text":"<p>Scarf provides you the ability to collect custom telemetry from within your application by utilizing our API. To enable this you'll need a Scarf account and a File Package created. Enable Event Collection Only.\u00a0</p> <p>Once this has been done, you can send telemetry data and associate it with the Scarf package you just created via HTTP requests to your configured endpoint. Here is a real world example from Unstructured.io in Python:</p> <p><pre><code># Copyright 2022 Unstructured Technologies, Inc\n# Licensed under the Apache License, Version 2.0\ndef scarf_analytics():\n       try:\n     # If either environment variable is set, do not collect metrics and exit.\n        if os.getenv(\"SCARF_NO_ANALYTICS\") != \"true\" and os.getenv(\"DO_NOT_TRACK\") != \"true\":\n            requests.get(\n          # ENDPOINT is a DNS CNAME configured within your Scarf account\n          # FILE_PACKAGE_NAME is the Scarf collection under which these data points will be collected\n                \"https://ENDPOINT.scarf.sh/FILE_PACKAGE_NAME?version=\"\n                + __version__\n                + \"&amp;platform=\"\n                + platform.system()\n                + \"&amp;python=\"\n                + python_version\n                + \"&amp;arch=\"\n                + platform.machine(),\n            )\n    except Exception:\n        pass\n</code></pre> Scarf has also published and maintains an example in bash or shell.</p> <p>Description:</p> <p>This function, <code>scarf_analytics()</code>, is responsible for collecting and sending telemetry data about the current system environment to a server you host. This data helps users understand how their Python library is being used across different platforms and configurations.</p> <p>Functionality:</p> <ol> <li> <p>The URL we are making a request to is configured by the corresponding Scarf package entry. In this case, this is configured to be <code>https://packages.unstructured.io/python-telemetry</code></p> </li> <li> <p>Custom data parameters for the event can be sent via configured URL path segments or query parameters, depending on how your Scarf package routes are configured.</p> </li> </ol> <p>Important Notes:</p> <p>It\u2019s important to have mechanisms to track user opt-in/out. This function respects user privacy preferences according to multiple standards. Users can set the\u00a0 <code>DO_NOT_TRACK</code> environment variable or the <code>SCARF_NO_ANALYTICS</code> environment variable.</p>"},{"location":"data-export/","title":"Data Export","text":""},{"location":"data-export/#introduction","title":"Introduction","text":"<p>Scarf provides a robust platform for tracking package downloads and pixel views. The ability to export this data is crucial for analytics, reporting, and integrating with other tools. This guide aims to provide a clear and concise explanation of how to export data from Scarf, what data is exported, and how to make use of any available integrations.</p>"},{"location":"data-export/#prerequisites","title":"Prerequisites","text":"<p>Exporting data from Scarf will only work if you are on a Scarf Paid Plan.</p>"},{"location":"data-export/#how-to-export-event-data","title":"How to Export Event Data","text":""},{"location":"data-export/#scarf-dashboard","title":"Scarf Dashboard","text":"<p>To export data out of Scarf,</p> <ol> <li>go to the main dashboard and</li> <li>click \"Export packages data\".</li> </ol> <p>This will export all data, for the default period, over the past month.</p> <p></p> <p>The data you can export from Scarf includes all events (defined as package downloads and pixel views) from every user that has interacted with your Scarf-enabled artifacts (packages and pixels). Upon clicking \"Export packages data\", this data will download as a .csv file.</p>"},{"location":"data-export/#scarf-api","title":"Scarf API","text":"<p>You can also export this data using the Scarf API.</p>"},{"location":"data-export/#what-data-is-exported","title":"What Data is Exported","text":""},{"location":"data-export/#export-fields","title":"Export Fields","text":"<p>The event data export includes the following data fields</p> name type description id <code>text</code> This uniquely identifies the event (pixel view or package download) that occurred. type <code>text</code> This categorizes the type of event that occurred (e.g. pixel-fetch, manifest-fetch, binary-download, etc.). package <code>text</code> For Scarf package downloads, this specifies which package has been downloaded. pixel <code>text</code> For Scarf page views, this specifies which pixel has been downloaded. version <code>text</code> For Scarf package downloads, this specifies which version of the package has been downloaded. time <code>timestamp</code> This refers to the time in UTC that the event occurred. referer <code>text</code> For Scarf pixel views, this refers to the page that was viewed. user_agent <code>text</code> This refers to the User-Agent, which provides information around the method of installation, often including information such as operating system, device, browser, architecture, and client. variables <code>text</code> This refers to any custom-specified variables that you might use Scarf to track in file package downloads. origin_id <code>text</code> This uniquely identifies the user (through a specific device) who has interacted with a Scarf event. origin_latitude <code>numeric</code> This is the latitude of the location Scarf is able to identify for the event. origin_longitude <code>numeric</code> This is the longitude of the location Scarf is able to identify for the event. origin_country <code>text</code> This is the country of the location Scarf is able to identify for the event. origin_city <code>text</code> This is the city of the location Scarf is able to identify for the event. origin_state <code>text</code> This is the state of the location Scarf is able to identify for the event. origin_postal <code>text</code> This is the postal code (ZIP code, in the US) of the location Scarf is able to identify for the event. origin_connection_type <code>text</code> This categorizes the type of IP address Scarf is able to identify (e.g. business, isp, hosting, etc.). origin_company <code>text</code> If Scarf is able to associate the event with a known business entity, that business entity is listed here. origin_domain <code>text</code> If Scarf is able to associate the event with a known business entity, that business entity's web domain address is listed here. dnt <code>boolean</code> If the user includes a DNT request in their header, that is logged here and they will not be tracked. confidence <code>numeric</code> The probability of correct identification of the data. endpoint_id <code>text</code> This uniquely identifies the public-facing device that has interacted with a Scarf event. Unlike origin_id, it is notably not sensitive to changes in device information like client, user agent, etc. mtc_quota_exceeded <code>boolean</code> A value of <code>true</code> indicates the company information from the event data row was scrubbed due to exceeding the MTC limit."},{"location":"data-export/#how-to-export-aggregate-data","title":"How to Export Aggregate Data","text":"<p>The documentation for exporting aggregates can be found in Export aggregates. Here's an example curl request to download aggregate data. The output is newline delimited json. <pre><code>curl -o {filename}.jsonl \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/x-ndjson\" \\\n\"https://api.scarf.sh/v2/packages/{owner}/aggregates?start_date={start_date}&amp;end_date={end_date}&amp;breakdown=by-company\"\n</code></pre></p>"},{"location":"data-export/#how-to-export-company-data","title":"How to Export Company Data","text":"<p>The documentation for exporting company data that is rolled up with a daily interval can be found in Export Company Data</p> <p>Here's an example curl request to download company rolled up data. <pre><code>curl -o company-rollup.csv \\\n-H \"Authorization: Bearer {token} \\\n    -H \"Content-Type: text/csv\" \\\n    https://api.scarf.sh/v2/packages/{owner}/company-rollup\n</code></pre></p> <p>The company data export includes the following data fields.</p> name type description company_name <code>text</code> Name of the company company_domain <code>text</code> Domain of the company. Eg. scarf.sh funnel_stage <code>text</code> Stage of a company's journey in using your software total_events <code>numeric</code> Count of total events unique_sources <code>numeric</code> Number of distinct sources of traffic that comprise the total event count from this organization. first_seen <code>text</code> Date of when the first event occured last_seen <code>text</code> Date of when the last event occured company_linkedin_url <code>text</code> A company's LinkedIn link company_industry <code>text</code> A company's industry. Eg. Tech, Government, etc. company_size <code>text</code> A company's approximated employee count company_country <code>text</code> A company's country location company_state <code>text</code> A company's state location interest_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the interest funnel_stage investigation_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the investigation funnel_stage experimentation_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the experimentation funnel_stage ongoing_usage_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the ongoing usage funnel_stage inactive_start_date <code>text</code> <code>format: yyyy-mm-dd</code> Date when a company started in the inactive funnel_stage"},{"location":"data-export/#how-to-export-company-events","title":"How to Export Company Events","text":"<p>The documentation for exporting company events can be found in Export Company Events. Here's and exampe curl request to download company events data. <pre><code>curl -o company-events.csv \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: text/csv\" \\ \n\"https://api.scarf.sh/v2/companies/{owner}/{domain}/events?start_date={start_date}&amp;end_date={end_date}\"\n</code></pre> The fields for this export can be found here</p>"},{"location":"data-export/#integrations","title":"Integrations","text":""},{"location":"data-export/#scarf-to-postgresql","title":"Scarf to PostgreSQL","text":"<p>GitHub: https://github.com/scarf-sh/scarf-postgres-exporter</p>"},{"location":"data-export/#overview","title":"Overview","text":"<p>The Scarf to PostgreSQL Exporter is a script designed to pull down your raw Scarf data and send it into a PostgreSQL database. This script is intended to be run as a daily batch job. It provides an automated way to backfill and update your PostgreSQL database with Scarf's enhanced data.</p>"},{"location":"data-export/#prerequisites_1","title":"Prerequisites","text":"<ul> <li><code>psql</code> must be installed and available in your environment (or use the Docker container with everything you need). </li> <li>A Scarf Account.</li> <li>Your Scarf API token. You can find your API Token from your user settings page.</li> </ul>"},{"location":"data-export/#settings","title":"Settings","text":"<p>The following environment variables are required:</p> <ul> <li><code>SCARF_API_TOKEN</code>: Your Scarf API access token.</li> <li><code>SCARF_ENTITY_NAME</code>: Your Scarf username or the name of your organization.</li> <li><code>PSQL_CONN_STRING</code>: The PostgreSQL connection string.</li> </ul> <p>optional</p> <ul> <li><code>BACKFILL_DAYS</code>: Number of days to backfill data. Defaults to 31 if not set.</li> </ul>"},{"location":"data-export/#getting-started","title":"Getting Started","text":"<p>For more details, you can visit the GitHub repository.</p>"},{"location":"data-export/#future-integrations","title":"Future Integrations","text":"<p>Integrations are in development, if you have particular data sources you'd like Scarf to integrate with, we'd love to hear from you.</p>"},{"location":"data-export/#daily-scheduled-exports","title":"Daily Scheduled Exports","text":"<p>Schedule a daily export via the API endpoint https://api.scarf.sh/v2/exports/{owner}/schedule-export. This export has the capability to export both raw events and company rollup aggregated data to the bucket indicated in the s3_uri_destination field. The S3 uri that you submit will be considered as the bucket name. Do not specify an object key. The service will generate the object key with the format <code>&lt;events|company-rollups&gt;-scarf-export-&lt;start date&gt;-&lt;end date&gt;.csv</code>. </p> <p>Setting up your S3 account</p> <p>Create a policy that states we can assume a role. Here's an example of that policy. This example is a highly permissive role. If you want to customize the role, please refer to the proper AWS documentation. <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"sts:AssumeRole\",\n\"sts:*\"\n],\n\"Resource\": \"*\"\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:*\"\n],\n\"Resource\": [\n\"arn:aws:s3:::&lt;bucket-name&gt;/&lt;folder-a&gt;/&lt;subfolder-a&gt;/*\"\n]\n}\n]\n}\n</code></pre> After creating the policy, create a role and attach the policy. Once you've created the role, you should have an ARN that looks like this <pre><code>arn:aws:iam::&lt;account-id&gt;:role/&lt;role-name&gt;\n</code></pre> The easiest way to create a role is to pick \"AWS Account\" in the \"Select trusted entity\" section. Then in the \"An AWS Account\", pick \"Another AWS Account\". This will ask for an account aws account id. This is where you will put in scarf's account id <code>032190491485</code>.</p> <p>After creating the role, go to the \"Trust relationships\" and add the following trust policy <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::032190491485:user/production-v2-scarf-server\"\n},\n\"Action\": \"sts:AssumeRole\"\n}\n]\n}\n</code></pre></p> <p>The ARN role is what you will need in the <code>arn_role</code> api field.</p> <p>This is not an exhaustive documentation of how to setup a shared s3 bucket. Please refer to the AWS documentation for more information.</p>"},{"location":"event-import/","title":"Importing Events","text":"<p>See API Docs here: api-docs.scarf.sh/v2.html#tag/External-event-import</p> <p>You can bring your events from other applications and platforms into Scarf with the Event Import API. Your imported events will be enriched by Scarf asynchronously, and your enriched data will be available through the app and the Data Export.</p> <p>We provide three main ways to import events:</p> <ul> <li>Importing into a single package</li> <li>Importing into a single pixel</li> <li>Importing into multiple packages and pixels by providing IDs in each row</li> </ul> <p>Warning</p> <p>The Event Import will only process fields prefixed with <code>$</code> . You will be required to provide date-time using the <code>$time</code> field at minimum (ISO or timestamp), and you may want to provide a unique identifier for each event using <code>$unique_id</code> . Note that this <code>$unique_id</code> will override previous events if reused. For importing multiple packages and pixels, you will have to provide the relevant ID through the <code>$package</code> and <code>$pixel</code> fields. See the API docs for more details: https://api-docs.scarf.sh/v2.html#tag/External-event-import/operation/importEvents</p> <p>Danger</p> <p>The Event Import API is meant to handle large, bundled imports, and is limited to 15 concurrent imports. Past this limit, you will get a 422: too many active imports error. To avoid running into this problem, make sure to batch your imports if you have automation to bring data into Scarf.</p>"},{"location":"event-import/#getting-started","title":"Getting Started","text":"<p>To get started, create packages and pixels in your account to import data into them. You will need to get IDs from the packages and pixels you want to import data into.</p>"},{"location":"event-import/#importing-into-a-single-package","title":"Importing into a single package","text":"<p>You will need to get the ID of your package from Scarf from the app or the List packages endpoint. Once you have your ID, you can start sending your events to Scarf from our Package Event Import endpoint.</p> <p>Info</p> <p>You may want to save the ID returned from the Imports API, in case you need to cancel the import or see its status later. You can also call the imports list endpoint to get a list of your imports and their statuses even if you don\u2019t save the ID from here.</p> <p>Warning</p> <p>The Event Import will only process fields prefixed with <code>$</code> . You will be required to provide date-time using the <code>$time</code> field at minimum (ISO or timestamp), and you may want to provide a unique identifier for each event using <code>$unique_id</code> . Note that this <code>$unique_id</code> will override previous events if reused.</p> <p>Example</p> <p>api.scarf.sh/v2/packages/{owner}/{package_id}/import</p> <p>events.ndjson</p> <pre><code>{\"$remote_address\":\"152.241.796.177\",\"$time\":\"2024-06-04T00:00:00Z\",\"$unique_id\":\"c20b1271-fb3f-abfa-df12-ef3cda4b2aa0\"}\n{\"$remote_address\":\"600.188.717.651\",\"$time\":\"2024-06-01T00:00:00Z\",\"$unique_id\":\"9053a19a-15a9-3695-bd37-b055a45949c1\"}\n{\"$remote_address\":\"665.921.984.205\",\"$time\":\"2024-06-25T00:00:00Z\",\"$unique_id\":\"09b5b69a-0af0-8002-2c2b-39df3d5685a4\"}\n</code></pre> <p>import-to-package.bash</p> <pre><code>#!/usr/bin/env bash\n\ncurl -v \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/json\" \\\n-X POST https://api.scarf.sh/v2/packages/YourOrg/abc01234-0000-0000-0000-000000000000/import \\\n--data-binary @events.ndjson\n</code></pre> <p>This will import three events into the package with ID <code>abc01234-\u2026</code> .</p>"},{"location":"event-import/#importing-into-multiple-packages-and-pixels","title":"Importing into multiple packages and pixels","text":"<p>Importing into multiple packages and pixels is the same as above, but require IDs from your packages and pixels. Make sure to include them in your events when your bring them into Scarf through the Multi-Artifact Event Import endpoint.</p> <p>Warning</p> <p>The Event Import will only process fields prefixed with <code>$</code> . You will be required to provide date-time using the <code>$time</code> field at minimum (ISO or timestamp), and you may want to provide a unique identifier for each event using <code>$unique_id</code> . Note that this <code>$unique_id</code> will override previous events if reused. For importing multiple packages and pixels, you will have to provide the relevant ID through the <code>$package</code> and <code>$pixel</code> fields. See the API docs for more details: https://api-docs.scarf.sh/v2.html#tag/External-event-import/operation/importEvents</p> <p>Example</p> <p>api.scarf.sh/v2/{owner}/import</p> <p>events.ndjson</p> <pre><code>{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"152.241.796.177\",\"$time\":\"2024-06-04T00:00:00Z\",\"$unique_id\":\"c20b1271-fb3f-abfa-df12-ef3cda4b2aa0\"}\n{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"600.188.717.651\",\"$time\":\"2024-06-01T00:00:00Z\",\"$unique_id\":\"9053a19a-15a9-3695-bd37-b055a45949c1\"}\n{\"$package\":\"970493a1-4ca0-4a4d-a085-fdce578e5a08\",\"$remote_address\":\"665.921.984.205\",\"$time\":\"2024-06-25T00:00:00Z\",\"$unique_id\":\"09b5b69a-0af0-8002-2c2b-39df3d5685a4\"}\n</code></pre> <p>import-multiple-artifacts.bash</p> <pre><code>#!/usr/bin/env bash\n\ncurl -v \\\n-H \"Authorization: Bearer {token}\" \\\n-H \"Content-Type: application/json\" \\\n-X POST https://api.scarf.sh/v2/YourOrg/import\n  --data-binary @events.ndjson\n</code></pre> <p>This will import three events into the package with ID <code>abc01234-\u2026</code> .</p>"},{"location":"event-import/#checking-import-status","title":"Checking Import Status","text":"<p>To check the status of your imports, you can use the Event Imports List endpoint.</p> <p>Example</p> <p>api.scarf.sh/v2/imports/{owner}</p> <p><code>curl [...] \"https://api.scarf.sh/v2/imports/YourOrg\"</code></p> <pre><code>{\n\"event_imports\": [\n{\n\"created_at\": \"2023-08-04T13:58:26.021037Z\",\n\"error_log_sample\": [\n{\n\"class\": \"error\",\n\"human_friendly_message\": \"Not a valid JSON object\",\n\"line\": 1,\n\"type\": \"failed-to-decode\"\n}\n],\n\"events_failed_to_import\": 1,\n\"events_successfully_imported\": 0,\n\"events_total\": 1,\n\"id\": \"0c4f966c-b715-497a-83e2-467254c95e40\",\n\"owner\": \"YourOrg\",\n\"status\": \"done\",\n\"updated_at\": \"2023-08-04T13:58:26.784432Z\",\n\"warning_log_sample\": []\n}\n]\n}\n</code></pre> <p>Alternatively, you can go to the Imports page in your organization settings to see a history of imports and see sample of warning and error logs:</p> <p></p>"},{"location":"event-import/#cancelling-imports","title":"Cancelling Imports","text":"<p>If you need to cancel an existing import, you can reference the import by its ID and call the Abort Event Import endpoint.</p> <p>If you haven\u2019t saved the ID from the import request, you can still find it from the Event Imports List endpoint.</p> <p>Example</p> <p>api.scarf.sh/v2/imports/{owner}/{event_import_id}/abort</p> <pre><code>$ curl [\u2026] -I -X POST \"https://api.scarf.sh/v2/imports/YourOrg/abc01234-0000-0000-0000-000000000000/abort\"\nHTTP/2 204\n</code></pre>"},{"location":"funnel-stages/","title":"Open Source Adoption Funnel Stages","text":"<p>Scarf analyzes how companies interact with your open-source project to infer their progress toward adopting it. Funnel Stages represent the portion of the user journey that best describes any given company or lead, from the moment they learn of your project, to when they deploy it to production, and beyond.\u00a0</p> <p>All paid subscribers and active trial participants will see a Funnel Stage on Company Views/Downloads in your Package and Pixel Analytics. Funnel Stages begin at the most basic level with interest, increasing all the way to ongoing usage.</p> <p></p> <p>As events by a user/organization occur, such as views or downloads, Scarf assigns point values to them. Those points add up over time as a user moves into different stages of the funnel. The frequency of activity is also considered, and points can be removed as the time between activities increases and the perceived interest or likelihood to adopt decreases.\u00a0</p> <p>Scarf\u2019s funnel stages are as follows:</p>"},{"location":"funnel-stages/#interest","title":"Interest","text":"<p>A company enters this stage following initial events such as viewing your documentation, README, or site (pixel activity only - a download would trigger the investigation stage). \u00a0\u00a0</p>"},{"location":"funnel-stages/#investigation","title":"Investigation","text":"<p>Enough activity has occurred for us to suspect the user/organization is actively investigating your OSS. This stage includes the occurrence of multiple events such as at least one package download with multiple docs views or at least two weeks of consecutive pixel view activity, and the company has been active in the last 30 days.\u00a0</p>"},{"location":"funnel-stages/#experimentation","title":"Experimentation","text":"<p>Sufficient activity has occurred for us to suspect the company is actively trying your OSS, but might not be relying on it in a production workload yet. Events such as multiple downloads and page views will have occurred over 30 days, or a single download and multiple page views over 60 days.\u00a0The origanization may be in the development with your OSS, or prototyping, or running internal tests. We don't yet have enough evidence to make stronger conclusions about production usage.</p>"},{"location":"funnel-stages/#ongoing-usage","title":"Ongoing Usage","text":"<p>By this stage, Scarf has enough data to conclude the company is using your software in an ongoing manner, potentially in a production environment.  Companies in this stage may be ready to become paying customers and should be moved into your sales/marketing pipeline where available. For non-commercial open-source projects, companies in this stage may be good sponsorship targets or valuable advocates in the community. These companies will have event activity over the course of the past 90 days, such as continued downloads or views.</p>"},{"location":"funnel-stages/#inactive","title":"Inactive","text":"<p>Companies may move into an inactive stage when activity drops off and does not resume over 60 or more days. If activity resumes, the company will return to the last active stage.\u00a0</p>"},{"location":"funnel-stages/#recommended-sort","title":"Recommended Sort","text":"<p>The Recommended Sort reorders the list of companies in the activity table in descending order, first by their point value, then by number of events, and finally by most recent to oldest last seen value. This sort option lets you view the companies most worthy of your attention first.\u00a0</p> <p></p>"},{"location":"funnel-stages/#company-journey","title":"Company Journey","text":"<p>When selecting a company to view in greater detail from any of the Company analytics charts, Administrators will see greater detail within the Company Journey. The company\u2019s current funnel stage will be displayed in the top left, next to STATUS. Hover over the graphical calendar in the Company Journey to see details of the views and downloads that occurred over time. Below the graphical calendar are aggregated views of the total activity within each stage, including the current stage.\u00a0</p> <p></p>"},{"location":"funnel-stages/#event-importance","title":"Event Importance","text":"<p>Event Importance allows you to determine the weight that certain events carry over others. For instance, a download should carry more weight than a page view on your public website as it shows higher interest. This importance can be defined when setting up a new pixel or package and can be edited anytime. The importance will default to medium.\u00a0</p> <p>You\u2019ll see the Event Importance noted on the Events detail charts.\u00a0</p> <p></p> <p>Use the Event Importance slider to set or edit the importance of a Package or Pixel.\u00a0</p> <p></p>"},{"location":"funnel-stages/#using-your-scarf-funnel-stage-data","title":"Using Your Scarf Funnel Stage Data","text":"<p>Scarf's data combines lead scoring's best features with intent data. Real-time activity highlights the companies actively researching and testing your open-source software. This data facilitates operationalizing the usage and intent data provided by your Scarf Gateway.\u00a0Utilize the data to track trends in usage over time to indicate your ideal customer profile, highlight opportunities and risks, such as early indicators of potential churn, or documentation that needs more frequent updating.</p> <p>Sudden and/or unexpected changes in activity levels or types may indicate a company looking to make a change. While this change may be good or bad, it is worthy of attention and investigation. Key examples include:</p> <ul> <li> <p>A previously consistent user goes inactive</p> </li> <li> <p>An existing paying customer of yours becomes very active with OSS, potentially indicating a downgrade before it actually happens</p> </li> <li> <p>You begin to see more traffic to documents explaining data export by certain users</p> </li> </ul>"},{"location":"funnel-stages/#go-even-further-with-your-outreach","title":"Go Even Further with Your Outreach","text":"<p>If you\u2019re interested in going beyond the company-level data that Scarf provides in our OQLs and Funnel Stages, Scarf can help you procure a list of individuals with contact information that may be good target leads at your target companies. If interested, please contact Scarf Support to discuss our Lead Generation services.\u00a0</p>"},{"location":"gateway/","title":"Scarf Gateway","text":""},{"location":"gateway/#overview","title":"Overview","text":"<p>Scarf Gateway is a service that sits in front of your existing software hosting platform(s), acting as a single access-point to all of your artifacts, regardless of where they are actually hosted. By making it easy to host content from your own domain, Scarf Gateway decouples your distribution from your hosting provider and provides in-depth download analytics.</p> <p>Suppose you maintain a Docker container image <code>acme/rocket-skates</code> on Docker Hub. Your users would normally pull your container image from Docker hub directly (<code>docker pull acme/rocket-skates</code>.) Using Scarf, they would pull from Scarf Gateway using your private domain (<code>docker pull docker.acme.com/acme/rocket-skates</code>.) Important analytics are recorded and shared with you while you are using Scarf and you may change your hosting providers at any time without changing your container image name or documentation.</p> <p>Your users will always be using your domain to pull your Docker container images. Your Docker container images can stay on their current hosting provider, but will be served through your own domain, e.g.:</p> <pre><code># Make your existing container available through your own domain\n$ docker pull docker.acme.com/acme/rocket-skates\n\n# Scarf provides a domain too if you'd prefer to use ours\n$ docker pull acme.docker.scarf.sh/acme/rocket-skates\n</code></pre> <p>Data insights about your Docker container image's downloads can be found in your Scarf Dashboard. From there, you can also manage Scarf Gateway configuration, access controls, and more.</p>"},{"location":"gateway/#configuring","title":"Configuring","text":""},{"location":"gateway/#scarf-package-entries","title":"Scarf Package Entries","text":"<p>Everything that is served and tracked via Scarf Gateway needs a corresponding package entry on scarf.sh. Configuration, analytics, and permissions are all done at the level of a package, or single repository. <code>rocket-skates</code>, <code>acme/rocket-skates</code> are all valid package entries. Because packages can seamlessly change their hosting provider, hostnames (e.g. <code>gcr.io</code>) are not part of the package identifier on Scarf (e.g. <code>acme/rocket-skates</code> and not <code>gcr.io/acme/rocket-skates</code>.)</p> <p>To create your package entry, click \"New Package\" in the navbar in your Scarf dashboard. Then select the corresponding package type for your artifact.</p>"},{"location":"gateway/#container-image-packages","title":"Container Image Packages","text":"<p>Scarf Gateway configuration for a Docker container image entry has two main considerations:</p> <ul> <li>Backend URL: This refers to where your container is actually hosted, the location where Scarf will direct requests to pull the container. Scarf will ask for your container's current pull command. This could be <code>rocket-skates</code>, <code>acme/rocket-skates</code> (implicitly specifying Docker Hub as the hosting provider, <code>registry-1.docker.io/acme/rocket-skates</code>), or a fully qualified container image name <code>docker.acme.come/acme/rocket-skates</code>. You can modify this backend URL attribute later, and your user's Docker pulls will be instantly moved over to the new destination without having to communicate anything to them.</li> <li>Domain: This can be your own domain, or a Scarf-supplied domain, of the form <code>&lt;username&gt;.docker.scarf.sh</code>. By default your Scarf domain will be used if this field is left empty. Note that this will be part of your Docker pull command for your users. While you can update this domain, updating your public domain is a breaking change for any users on the current domain! Edit this value with caution.</li> </ul> <p>If you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code>. Additionally we require you to verify your ownership of the domain by setting a TXT with a value that Scarf provides upon package creation. See your DNS provider's instructions for how to add CNAME and TXT records.</p> <p>See Figure 0 to see how these pieces fit together visually.</p>"},{"location":"gateway/#file-packages","title":"File Packages","text":"<p>File Packages on Scarf are a flexible and low-level package type that can track visits and downloads on arbitrary URLs. File packages were originally created to track published tar balls, but it has since expanded to many other use cases and will likely be renamed in future versions of Scarf. You can think of File Packages as a powerful and fully customizable link shortener. Common use cases include:</p> <ul> <li>Tracking downloads of GitHub release artifacts</li> <li>Tracking downloads of every artifact on your company/project \"downloads\" page</li> <li>Tracking downloads of Homebrew packages from a tap/formula that you control</li> <li>Sending custom telemetry or other events from your application</li> <li>Tracking and attributing visits to marketing and sales content on your site.</li> </ul> <p></p> <p>Scarf Gateway configuration for a file package entry has a few main considerations:</p> <ul> <li>Domain: Just like Docker container images, you may choose to use your own domain(s) for serving files. You may also choose to use <code>&lt;username&gt;.gateway.scarf.sh</code> provided by default by Scarf. Remember, if you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code> as well as verify ownership of that domain.</li> <li>Incoming Path: This refers to where a path on a given domain where Scarf will direct requests to fetch a file asset. This could be static path like <code>/downloads/rocket-skates.tar.gz</code> or a template path with variables like <code>/files/{version}/{platform}/rocket-skates-{platform}-{version}.tar.gz</code>. You may use variables in your incoming path as specified in RFC 6570. You can modify a path value later, but be careful to communicate to your users because this would be a breaking change.</li> <li>Outgoing URL: This is an optional full URL to your asset on your HTTP/S hosting provider. It is a template (or static) URL that may also use any variables defined in the Incoming Path. For example <code>https://besthostingprovider.com/acme/{platform}/rocket-skates-{version}.tar.gz</code>. If an Outgoing URL is not provided, the Gateway will return 200 with no redirect.</li> <li>Catch-all redirects: Select this option if you intend to configure a domain-level redirect with your File Package (ie, redirecting <code>site.com/*</code> -&gt; <code>anothersite.com/*</code>).</li> <li>Event collection only: Select this option if you intend to use Scarf Gateway as a telemetry endpoint to send events from your code, and do not intend to redirect your user to another URL or artifact to download. Packages configured with this option will not return a redirect to the client that sends a matching request. Scarf will instead return a simple 200 status code indicating that the event was received successfully.</li> </ul> <p>See Figure 3 to see how these pieces fit together visually.</p>"},{"location":"gateway/#python-packages","title":"Python Packages","text":"<p>Scarf Gateway configuration for a Python package entry has three main considerations:</p> <ul> <li>pip Command: This is the current pip command used to install your package. For packages on PyPI.org, this will be of the form <code>pip install my-pkg</code> and will include the <code>--extra-index-url https://my-python-project-domain.com</code> if your package is hosted elsewhere. This defines the location where the users will be redirected to when installing your package.</li> <li>Domain: This can be your own domain, or a Scarf-supplied domain, of the form <code>&lt;username&gt;.gateway.scarf.sh</code>. By default, your Scarf domain will be used if this field is left empty.</li> </ul>"},{"location":"gateway/#installing-python-packages-via-requirementstxt","title":"Installing Python packages via requirements.txt","text":"<p>Add the --extra-index-url option at the top of your requirements.txt:</p> <pre><code>--extra-index-url https://my-python-project-domain.com/simple/\nmy-pkg==0.0.1\n</code></pre> <p>NOTE: We have noticed indeterminate behavior in some versions of Pip that have resulted in the public registry being used for download regardless of the --extra-index-url addition. This is a client-specific problem and we are investigating.</p> <p>If you elect to use your own domain, you'll need to add a CNAME for that domain to <code>gateway.scarf.sh</code>. Additionally we require you to verify your ownership of the domain by setting a TXT with a value that Scarf provides upon package creation. See your DNS provider's instructions for how to add CNAME and TXT records.</p>"},{"location":"gateway/#how-it-works","title":"How it works","text":"<p>When a user requests a Docker container image through Scarf, Scarf simply issues a redirect response, pointing to whichever hosting provider you've configured for your container. Certain container runtimes do not handle redirects appropriately during authentication (which is required even for anonymous pulls), and, in those cases, Scarf will proxy the request to the host instead of redirecting. For a visualization of the system from the end-user's perspective, see Figure 1. For an overview of the entire system, Figure 2.</p> <p>When a user requests a file through Scarf, Scarf simply issues a redirect response, pointing to whichever hosting provider you've configured for your file. For a visualization of the system from the end-user's perspective, see Figure 4. For an overview of the entire system, Figure 5.</p> <p>Dashboard and Data Access</p> <p>Your package's usage data will be made available to you in your Scarf dashboard. You can grant others access to your package's usage data as well from your package details page. Current permission levels supported are:</p> Access Level Description Owner Can read all package-level data, edit package configuration, and grant access to other members Admin Can read all package-level data, edit package configuration, and grant access to other members (but can't remove other admins) Member Can read all package-level data <p>Scarf does not yet support organization-level permissions but will soon.</p>"},{"location":"gateway/#docker-packages-defining-a-container-pull","title":"Docker Packages: Defining a container pull","text":"<p>Scarf defines a pull based on how Docker Hub defines them for the purposes of their rate-limiting functionality.</p> <p>A pull is defined as one or more <code>GET</code> requests on hosting provider manifest URLs (<code>/v2/*/manifests/*</code>). <code>HEAD</code> requests are not counted as a pull.</p> <p>Note that even if a client downloads the blobs that comprise any given container, the container's manifest file may already be cached on the client, meaning the download would not be counted in Scarf's analytics. Future versions of Scarf's data processing pipelines will be more intelligent and will track things like partial downloads, blob fetches, etc.</p>"},{"location":"gateway/#security","title":"Security","text":"<p>All interactions through Scarf Gateway occur over HTTPS. Scarf Gateway will procure a valid TLS certificate via LetsEncrypt, and perform TLS termination for the traffic. Scarf Gateway in turn will issue a redirect for the request, or proxy the request to the hosting provider.</p>"},{"location":"gateway/#do-not-track","title":"Do Not Track","text":"<p>Our gateway respects the HTTP Headers as defined in DNT and GPC. If you send an HTTP request to our Scarf Gateway with the HTTP header \"DNT=1\" or \"Sec-GPC=1\", we will not count your request in our statistics nor will we lookup your IP address to determine if you are a business. Basically, it will be as if you didn't request anything from our gateway but we will still serve the content to you.</p> <p>Please note that this behavior works for all packages and pixels that are served through our gateway. If users have DNT turned on in their browser settings, we will not track file downloads or pixel views.</p>"},{"location":"gateway/#availability","title":"Availability","text":"<p>Scarf Gateway is a free hosted service that is publicly provided as-is and as-available.</p> <p>Scarf Gateway is deployed on AWS in multiple regions around the globe; it is fault tolerant even to entire regions going offline, and can automatically scale our backend capacity to meet whatever user traffic demands of us.</p> <p>We aim for a monthly service uptime percentage of 99.9%. If you need uptime and/or support SLAs to guarantee that uptime for your company, please contact sales@scarf.sh</p> <p>To see Scarf's historical uptime and system status, you can view the status page here.</p>"},{"location":"gateway/#badges","title":"Badges","text":"<p>All packages on Scarf Gateway offer dynamic Scarf-powered README badges automatically. Head to your package page, and the badges will be shown in the details section near the top. Copy the URL, paste it into your project\u2019s README based on whatever doc format you are using and you\u2019re all set.</p> <p></p> <p>What is the difference between the downloads badge and the company badge?</p> <p>The commercial usage badge shows how many distinct companies have been identified to be fetching your Scarf Gateway package in the previous month. The downloads badge reports the total number of downloads across all users.</p> <p>What is the purpose of this badge?</p> <p>README badges let you show off your project by sharing high-level real-time data about your download traffic and commercial adoption, so readers can quickly assess some basic details about your project. Scarf-powered README badges are an easy way to share your project\u2019s usage data publicly, regardless of where on the internet your docs are being rendered. Telling prospective new users how many companies use your project is a great way to show that your project is reliable and worth adopting.</p> <p>What is the URL format of the badges</p> <p>The badges can be used in the following formats:</p> <ul> <li> <p>Company Badge</p> <ul> <li>https://scarf.sh/package/company-badge/{package-id}</li> <li>https://scarf.sh/company-badge/{username}/{package-name}?package-type={package-type}</li> </ul> </li> <li> <p>Downloads Badge</p> <ul> <li>https://scarf.sh/package/installs-badge/{package-id}</li> <li>https://scarf.sh/installs-badge/{username}/{package-name}?package-type={package-type}</li> </ul> </li> </ul> <p>You can also pass some additional settings to your badges via query strings: <code>color</code>, <code>label-color</code>, <code>logo</code>, <code>logo-color</code> and <code>style</code>. For example, <code>https://scarf.sh/package/installs-badge/{package-id}?color=red&amp;style=flat</code>. See https://shields.io/#colors to know more about the supported values for each setting.</p>"},{"location":"gateway/#caveats-and-limitations","title":"Caveats and Limitations","text":"<p>A given subdomain can only point to a single container registry at a time.</p> <p>If you have Docker container images on multiple distinct registries, you'll currently need to use multiple distinct subdomains (one per hosting provider). This limitation is due to the current implementation of the Docker registry authorization. To begin pulling a container, an authentication request is sent, which must be passed to the hosting provider you configure Scarf Gateway to use. Unfortunately, the initial authorization request doesn't include any information about what image it's trying to pull all Scarf Gateway has to go on is the hostname used to begin to pull the Docker container image. Subsequent Docker API requests do the actual \"pulling\" of an image. The core of the problem is that, if you attempt to authorize with one registry and pull an image from another, it will fail with an authorization error.</p> <p>The path used in your container's new pull command must match the path on the backend container registry</p> <p>If your container is on Docker Hub as <code>acme/rocket-skates</code>, your install command must be: <code>docker pull ~&lt;your-domain.com&gt;/acme/rocket-skates</code>. The image name path (acme/rocket-status) is not something that can be changed at this time. This is due to the Docker client's OAuth implementation (authorization includes the image name path of the being requested.) If Scarf Gateway redirects to a different path, the authorization becomes invalid and the Docker pull will fail.</p>"},{"location":"gateway/#automatic-package-creation-for-containers","title":"Automatic Package Creation for Containers","text":"<p>Rather than creating packages entries for each container in your namespace, you can specify rules to automatically forward all matching traffic and create package entries automatically. By using a template, e.g. <code>repository/*</code>, every time an image matching that template is first downloaded, Scarf will automatically create a page for that package (e.g. repository/test01, repository/new-item).</p>"},{"location":"gateway/#creating-collections","title":"Creating Collections","text":"<p>To acces Collections, in the top menu click <code>Tools</code> &gt; <code>Collections</code>.</p> <p></p> <p>You will now be presented with the <code>Collections</code> page that give you the options to edit, delete, and create new collections.</p> <p></p> <p>To create a new collection, please first insert the template that will be used. It can be anything of the form: <code>repository/*</code>, <code>repository/{ variable1, variable2 }</code>, etc. Next, insert the backend domain, the domain where your images are hosted (e.g. registry-1.docker.io, ghcr.io, gcr.io). Please keep in mind, each public domain should map to one backend domain. (E.g. If you\u2019re using your Scarf domain for your images hosted on docker, you will not be able to use your Scarf domain for your images hosted on Amazon.) Submit your new rule!</p>"},{"location":"gateway/#faq","title":"FAQ","text":"<p>How do I get started using Scarf Gateway?</p> <p>First, create an account on Scarf, if you haven\u2019t already done so. Once you\u2019ve registered, you\u2019ll be prompted to create a new package. If you\u2019re already using Scarf, you\u2019ll be able to click \u201cNew Package\u201d in the navigation bar.</p> <p>Select \u201cDocker\u201d for your package type and enter in the requested details about your container. Scarf Gateway currently supports Docker containers. Support for more package and artifact types are on the way. Stay tuned.</p> <p>If I use a custom domain to host my container through Scarf, what happens to my existing users? Do they all have to update?</p> <p>Hosting containers on your custom domain via Scarf has no impact on your existing users; your domain adds a new path for users to download your package. You can encourage end-users to switch their pull commands over to your new domain, but they can continue pulling directly from your registry provider with no negative impact.</p> <p>Should you decide to switch registries later on, current users will have to update their pull commands to either your custom domain or to the new registry URL. If they go straight to the registry, they would need to update every time you decide to switch registries. If they use your custom domain, they will never need to update it again.</p> <p>Are you actually hosting my packages?</p> <p>No, your package continues to be hosted on your current hosting provider not on Scarf itself. Scarf Gateway is simply a thin redirect layer in front of your provider. Since Scarf Gateway acts as a stable location on the internet for your packages, you will always have the freedom to host them with any provider you choose.</p> <p>My Docker container image name on my current registry is <code>acme/rocket-skates</code>, can I change that to just <code>rocket-skates</code> when users pull through Scarf?</p> <p>Unfortunately this is not possible unless you can change this name on the registry that hosts your container. Your container name on Scarf must match the container name on the registry that hosts it, because the Docker client uses that name to sign the request and validate the response from the registry. The Docker client will reject the download if the response signature is invalid. See the Caveats section for more information.</p> <p>How are you managing the usage data you get about my project? Are you storing my users\u2019 data?</p> <p>Scarf Gateway does not store any personally identifying information or sensitive data about your users.</p> <p>Scarf looks up IP address metadata, but the raw IP addresses are discarded and never exposed. IP metadata may contain:</p> <ul> <li>Coarse-grained location</li> <li>Device/OS information</li> <li>Company information, cloud providers, etc.</li> </ul> <p>Additionally, Scarf sees metadata about the containers that are being downloaded such as:</p> <ul> <li>Tags/versions (variables)</li> <li>Client runtime and version</li> </ul> <p>What package types are you planning to support next?</p> <p>We\u2019d love your input to help us prioritize support for additional package types. Java, RPM and others are planned. Scarf Gateway will ultimately be generalized to support arbitrary artifact types.</p> <p>How much does it cost to use Scarf Gateway?</p> <p>Scarf Gateway\u2019s current feature set is free and will remain free. We will be adding additional functionality, features, service level agreements, and more, some free and some paid.</p> <p>Is Scarf Gateway self-hosted or managed by Scarf?</p> <p>Scarf Gateway is managed by the Scarf team. We plan an open source release of Scarf Gateway for self-hosting, when it is out of the current open beta period and into general availability.</p> <p>How long will it take for any given container download to show up in my analytics dashboard?</p> <p>Downloads will typically show up in your dashboard in 30 minutes and up to 2-3 hours.</p> <p>Is there an API I can use to pull my stats, manage my packages, etc?</p> <p>Yes! See our API documentation for more information.</p> <p>I have more questions, where is the best place to ask?</p> <p>Join us in Slack, we're more than happy to help.</p>"},{"location":"gateway/#figures","title":"Figures","text":""},{"location":"gateway/#figure-0-using-scarf-docker-gateway-as-a-maintainer","title":"Figure 0: Using Scarf (Docker) Gateway as a maintainer","text":""},{"location":"gateway/#figure-1-pulling-a-docker-container-image-from-scarf-docker-gateway-as-a-user","title":"Figure 1: Pulling a Docker container image from Scarf (Docker) Gateway as a User","text":""},{"location":"gateway/#figure-2-full-system-diagram-docker","title":"Figure 2: Full System Diagram (Docker)","text":""},{"location":"gateway/#figure-3-using-scarf-file-gateway-as-a-maintainer","title":"Figure 3: Using Scarf (File) Gateway as a maintainer","text":""},{"location":"gateway/#figure-4-downloading-a-file-from-scarf-file-gateway-as-a-user","title":"Figure 4: Downloading a File from Scarf (File) Gateway as a User","text":""},{"location":"gateway/#figure-5-full-system-diagram-file","title":"Figure 5: Full System Diagram (File)","text":""},{"location":"getting-started-checklist/","title":"Getting Started Checklist","text":"<ol> <li>Register for an account on the Scarf app.</li> <li>Set up and test downloads:<ol> <li>Set up a new package URL via the Scarf Gateway within your Scarf Dashboard.</li> <li>Point this URL to your current download endpoints.</li> <li>Update installation and setup documentation to direct users to use the gateway.</li> <li>Test the route either via your web browser, curl, or with wget.</li> <li>Check the dashboard to see if your download was registered.</li> </ol> </li> <li>Set up and test documentation or website tracking:<ol> <li>Create a Scarf tracking pixel</li> <li>Add it to the pages you want analytics for (whether on your site or on third-party sites).</li> <li>Check that the pixel is loading</li> <li>Return to the scarf dashboard and check for pixel view data</li> </ol> </li> <li>Set up and test link tracking and social monitoring:<ol> <li>Create a new URL in the Scarf Gateway as a redirect/link shortener to your website, YouTube, Hacker News, or other sites.  </li> <li>When posting links on social media, use the new URL instead of the main link.  Data will then be available in the Scarf dashboard.</li> </ol> </li> <li>Set up and test basic call home functionality:<ol> <li>Create a basic URL in Scarf Gateway that will act as an endpoint for your applications to ping.</li> <li>Point the URL to a blank page on your site.</li> <li>In your software, issue an async web call/ping/or page load using (your favorite tool/library/or command, i.e., curl/libcurl, etc.).  Note you can call this on start, daily, every time something runs, up to you.  You can throw away the result; the mere background call to open the URL is enough.</li> </ol> </li> <li>After testing the various methods you can use to measure downloads, views, and access with Scarf, build a plan for what you want to track and what sort of data you want to see. <ol> <li>Roll out tracking to all your projects/sites.</li> <li>Update your documentation and tutorials to point to your custom URL.</li> </ol> </li> <li>If you are looking to improve your lead flow, once you have data flowing into your system, fill out the lead generation form and get a trial of leads for your sales team coming directly from your download and web traffic.  </li> </ol>"},{"location":"oql/","title":"Open Source Qualified Leads ( OQLs )","text":""},{"location":"oql/#definition","title":"Definition","text":""},{"location":"oql/#what-is-an-open-source-qualified-lead-oql","title":"What is an Open Source Qualified Lead (OQL)?","text":"<p>An Open Source Qualified Lead (OQL) is an individual or organization that has shown a measurable level of engagement in open-source communities or projects, indicating a likely interest in a particular product or service that adds value to their open-source activities. This data-driven insight is crucial for identifying growth strategies, developer relations initiatives, and targeted sales or marketing campaigns.</p>"},{"location":"oql/#relevant-content-for-further-understanding","title":"Relevant Content for Further Understanding","text":"<p>By incorporating these broader concepts into the definition of an OQL, it becomes easier for everyone in an organization to understand and utilize the term effectively.</p>"},{"location":"oql/#lead-generation","title":"Lead Generation","text":"<p>In marketing, lead generation stimulates interest in a product or service to develop a sales pipeline. In the context of open source, this could involve tracking contributions, forum activity, or other community engagement metrics.</p>"},{"location":"oql/#lead-scoring","title":"Lead Scoring","text":"<p>This involves assigning a numerical value to each lead based on various factors like their level of interest, fit with the target market, and likelihood of becoming a customer. This could be based on the number of pull requests, issues raised, or other community contributions in the open-source context.</p>"},{"location":"oql/#lead-qualification","title":"Lead Qualification","text":"<p>This is the process of filtering leads based on specific criteria such as demographic information and behavioral actions. For OQL, this could involve analyzing the types of open-source projects they are involved in, their level of activity, and their expressed needs or pain points.</p>"},{"location":"oql/#why-should-you-track-oqls","title":"Why should you track OQLs?","text":"<ul> <li>Building a baseline and tracking the growth of your user base</li> <li>Planning activities to accelerate the adoption of your open source</li> <li>Enriching and expanding the sales pipeline</li> <li>Determining potential risk from users leaving your ecosystem</li> </ul>"},{"location":"oql/#oql-point-system","title":"OQL Point System","text":""},{"location":"oql/#page-views","title":"Page Views","text":"Event Value Points Limits Example(s) Low 0.25 \u2264 2 points/day\u2264 10 points/month Blog post view Medium 0.5 \u2264 3 points/day\u2264 20 points/month Home page view High 1 \u2264 5 points/day\u2264 30 points/month Pricing page view"},{"location":"oql/#downloadpullinstalls","title":"Download/Pull/Installs","text":"Event Value Points Limits Example(s) Low 2 \u2264 6 points/day\u2264 30 points/month Pull <code>latest</code> Medium 5 \u2264 10 points/day\u2264 50 points/month Pull a stable community edition release High 8 \u2264 16 points/day\u2264 42 points/month Pull an enterprise edition"},{"location":"oql/#community-activities","title":"Community activities","text":"<p>Additional recommended activities and events to be tracked based on community activity.</p> Event Value Points Limits Example(s) Low 2 \u2264 2 points/day\u2264 10 points/month Issue comment reaction Medium 5 \u2264 10 points/day\u2264 50 points/month Slack signup, open an issue High 8 \u2264 24 points/day\u2264 48 points/month Pull Request submitted"},{"location":"oql/#oql-status-levels","title":"OQL Status Levels","text":"<ol> <li>Interest - Just viewing docs or site, any downloads immediately trigger Investigation stage.<ol> <li>Less than 10 points.</li> <li>Just pixel activity -  any downloads trigger Investigation stage.</li> </ol> </li> <li>Investigation - Enough activity has occurred for us to suspect the company is actively investigating this open source<ol> <li>Has activily reached more than 10 points but less then 40.</li> <li>They have downloaded at least 1 package and poked around the docs (multiple pixels).</li> <li>Or, we see 2 consecutive weeks of pixel activity.</li> </ol> </li> <li>Experimentation - Enough activity has occurred for us to suspect the company is actively using this open source software for one or more production systems<ol> <li>Has activity that has reached 40 to 70 points.</li> <li>Multiple downloads and pixels over the course of 30 days.</li> <li>Or, single download and multiple pixels over the course of 60 days.</li> <li>and Active in the last 30 days.</li> </ol> </li> <li>Ongoing Usage - Enough activity has been detected for us to suggest that this user may be ready to be a customer and should feed into the sales/marketing pipeline if available. If this is not a commercial open-source project, OQL3 would be a good indicator that this company may be a good sponsorship target or may prove to be a valuable advocate in the in the community.<ol> <li>Has activity that has reached 70+ points.</li> <li>Continued downloads or pixel fetches, over 90 days of history, active in the last 90 days.</li> </ol> </li> <li>Inactive - Former OQL that qualified, but overtime has gone cold or is unverified.<ol> <li>We saw activity at some point, but we haven\u2019t seen anything in 60 days.</li> <li>Previously reach an Investigation, Experimentation, or Ongoing Usage status, but no longer meets this requirement.</li> </ol> </li> </ol>"},{"location":"oql/#practical-example","title":"Practical Example:","text":"<p>There are different ways to build an OQL depending on the project, outcome, and needs.  But for our example, let\u2019s say that we determine an OQL should perform the following:</p> <ul> <li>Download the software packages more than once over the course of more than 3 days<ul> <li>Indicating more than merely a passive one-time download.</li> </ul> </li> <li>Viewing the docs over the course of multiple days<ul> <li>The more unique people from the same company the better.</li> </ul> </li> <li>Active participation in 1 or more community channels (Github, Slack, forums, etc)<ul> <li>This shows more investment in understanding and using the software\u2026 but often only 1 out of 10 users will show up here.</li> </ul> </li> <li>Activity (either downloads, documentation views, Slack messages, etc) within the last 31 days</li> </ul> <p>Assuming you have seen a single company or person do the above activities, you have high confidence that this company is at least investigating your software.</p> <p>We could enrich this data even further by looking at things like:</p> <ul> <li>Activities over a 3 month or 6 month period<ul> <li>This would indicate ongoing usage.</li> </ul> </li> <li>Ongoing or repeated page views or searches for a specific feature or solution<ul> <li>This would help identify a potential desire to use or better understand a specific feature.  This could also represent a place where they are stuck.</li> </ul> </li> <li>Page views to pricing or signup pages<ul> <li>This, combined with ongoing activities over a sustained period, would indicate a strong potential interest for a commercial relationship.</li> </ul> </li> </ul> <p>If you are tracking a company's OQL status over time, this can help you estimate churn and understand potential changes in the sentiment of your project. Consider if you have a user who reached an Ongoing Usage and purchased something from your company. For 2 years this company has maintained this status. Then, for the last 2 months, they have not reached the same status. Why has their download pattern changed? Why did they stop participating in your community? Are they going to move to something else? Knowing this enables you to get ahead of any potential issue.</p>"},{"location":"oql/#sample-setup","title":"Sample Setup","text":"<p>Below we will outline a basic setup for scoring and qualifying OQL\u2019s.   We recommend starting with a simple point system to qualify leads over a 30/60/90 day period. In a point system each activity is worth a certain amount of points, once you reach a certain number of points and/or logic gates that moves a lead to the appropriate lead level. We also recommend that you track OQL\u2019s at the company level. Many of the activities will occur from servers and won\u2019t be associated with end user accounts.</p>"},{"location":"oql/#faq","title":"FAQ","text":""},{"location":"oql/#how-is-an-oql-different-from-an-mql","title":"How is an OQL different from an MQL?","text":"<p>A marketing qualified lead (MQL) is similar to an OQL but contains different activities and is focused on a different part of a user's journey.  While an OQL is tracking user and community activities, the MQL will track interactions with marketing activities.  We recommend overlapping webpage visits for both MQL\u2019s and OQL\u2019s, but other than that the OQL is focused on open source adoption, and then the MQL is focused on closing new commercial customers.</p> <p>An OQL could become an MQL which could eventually become an sales qualified lead (SQL).</p>"},{"location":"organizations/","title":"Organizations","text":""},{"location":"organizations/#creating-an-organization","title":"Creating an organization","text":"<p>To create an organization, in the header menu click on the <code>Organization</code> button</p> <p></p> <p>alternatively, you can access it via the plus icon and selecting <code>New Organization</code></p> <p></p> <p>If you haven't already setup an organization you will be presented with the following screen:</p> <p></p> <p>As you can see you are presented with two options:</p> <ol> <li> <p>Create Organization: This is if you are happy to keep your user and create a free standing organization.</p> </li> <li> <p>Convert Account to organization: If it happens that you've added lots of new packages and found that you'd like to put these under an organization umbrella this is the perfect way to achieve that.</p> </li> </ol>"},{"location":"organizations/#converting-your-current-account-to-an-organization","title":"Converting your current account to an organization","text":"<p>If your current username is what you would like your organization to be called, you can convert your account into an organization. To do this, please follow the steps below:</p> <p>From the splash screen shown above click on <code>Convert Account to organization</code>. You will be presented with the following:</p> <p> Click on <code>Get Started</code> and you will see:</p> <p></p> <p>You now need to select a new username as your current username will be converted into an organization and the new username will be the owner of this newly created organization. Fill in the other inputs as required.</p> <p>Lastly before clicking <code>Save</code> be mindful that all of your account\u2019s packages will be transferred to the organization.</p> <p>That's it you have now converted your account into an organization, the next screen you will see is the organization screen.</p> <p></p> <p>Now as previously prompted log out and back into your account. You will be presented with the following home page just like when you first open your account. Do not be alarmed, not all is lost it's just that all your data/packages have been transferred to your new organization. </p> <p>To access these you now have access to new menu items in the top right header menu, it will look as follows:</p> <p></p> <p>Now select the organization and you will see all of your previously created packages and data.</p> <p>A little helpful feature is when looking at the top right header menu you will now see two circles. The larger being what organization you are accessing and the smaller one being the user you are doing it with.</p> <p></p> <p>If you ever want to go back to your user then simply select it in the dropdown menu.</p>"},{"location":"organizations/#directly-creating-an-organization","title":"Directly creating an organization","text":"<p>In a very similar fashion to the converting you current account to an organization, simply select the option from the plus icon dropdown menu. </p> <p>The next screen will prompt you to add your new organization name and other details, click <code>Save</code> </p> <p>Et voil\u00e0! You now have new organization</p> <p></p>"},{"location":"organizations/#managing-your-organization","title":"Managing your organization","text":""},{"location":"organizations/#data-providers","title":"Data providers","text":"<p>Scarf partners with 3rd party data providers in order to surface IP-address metadata like the location or company behind any event in your account.</p> <p>Scarf's enhanced company matching capabilities feature a Clearbit integration to help us offer best-in-class data quality. Enabling Clearbit for your organization is free! Additional terms apply.</p> <p>To enable this Clearbit for your organization, navigate to your organization overview page, and find the section <code>Toggle Data Providers</code>. It is not enabled by default.</p> <p></p> <p>Complementary Clearbit access is already included in your Scarf plan</p> Scarf Tier Included Clearbit calls per month Free 10,000 calls/month included (for a limited time) Basic 10,000 calls/month included Premium 25,000 calls/month included, with pay-per-usage upgrades <p>For more information about enhanced company insights, contact our sales team.</p>"},{"location":"package-analytics/","title":"Scarf SDKs for library and package authors","text":"<p>Scarf's programming language SDKs provide observability into the usage of your libraries and language-specific packages. By adding a dependency to scarf-js or another Scarf language-level library, you can gain better data insights into how your package is used, and by which companies.</p>"},{"location":"package-analytics/#javascript","title":"JavaScript","text":""},{"location":"package-analytics/#features","title":"Features","text":"<ul> <li>Collects basic installation statistics on <code>npm install</code>.</li> <li>No dependencies</li> <li>Fully transparent to the user. Scarf will log its behavior to the console during installation. It will never silently report analytics for someone that hasn't explictly given permission to do so.</li> <li>Never interrupts your package installation. Reporting is done on a best effort basis.</li> </ul> <p>You can find scarf-js on GitHub or on npm directly.</p>"},{"location":"package-analytics/#installation","title":"Installation","text":"<p>You'll first need to create a package entry on Scarf. Be sure to select \"External library\", and set the package type to \"npm\".</p> <p>Once created, add a dependency on this library to your own:</p> <pre><code>npm i --save @scarf/scarf\n</code></pre> <p>Once your library is published to npm with this change, Scarf will automatically collect stats on install, no additional code is required!</p> <p>Head to your package's dashboard on Scarf to see your reports when available.</p>"},{"location":"package-analytics/#how-does-it-work","title":"How does it work?","text":"<p><code>scarf-js</code> registers a <code>postInstall</code> hook that sends telemetry information. This library has no runtime footprint, it only runs at installation time, when a developer runs <code>npm install</code> Continue reading below here</p>"},{"location":"package-analytics/#configuration","title":"Configuration","text":"<p>Users of your package will be opted in by default and can opt out by setting the <code>SCARF_ANALYTICS=false</code> environment variable. If you'd prefer to set Scarf analytics  such that users will be opted out by default instead, you can set this by adding an entry  to your <code>package.json</code></p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"defaultOptIn\": false\n  }\n  // ...\n}\n</code></pre> <p>Scarf will now be opt-out by default, and users can set <code>SCARF_ANALYTICS=true</code> to opt in.</p> <p>Regardless of the default state, Scarf will log what it is doing to users who haven't explictly opted in or out.</p> <p>By default, scarf-js will only trigger analytics when your package is installed as a dependency of another package, or is being installed globally. This ensures that scarf-js analytics will not be triggered on <code>npm install</code> being run within your project. To change this, you can add:</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"allowTopLevel\": true\n  }\n  // ...\n}\n</code></pre>"},{"location":"package-analytics/#faq","title":"FAQ","text":""},{"location":"package-analytics/#what-information-does-scarf-js-provide-me-as-a-package-author","title":"What information does scarf-js provide me as a package author?","text":"<ul> <li>Understanding your user-base</li> <li>Which companies and organizations are using your package?</li> <li>Is your project growing or shrinking? Where? On which platforms?</li> <li>Which versions of your package are being used?</li> </ul>"},{"location":"package-analytics/#what-information-does-scarf-js-send","title":"What information does scarf-js send?","text":"<p>See more here.</p>"},{"location":"package-analytics/#as-a-user-of-a-package-using-scarf-js-how-can-i-opt-out-of-analytics","title":"As a user of a package using scarf-js, how can I opt out of analytics?","text":"<p>Scarf's analytics help support developers of the open source packages you are using, and provide data insights to help improve their software, so your opt-in is appreciated. However, if you'd like to opt out, you can add your preference to your project's <code>package.json</code>:</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"enabled\": false\n  }\n  // ...\n}\n</code></pre> <p>Alternatively, you can set this variable in your environment:</p> <pre><code>export SCARF_ANALYTICS=false\n</code></pre> <p>Either route will disable Scarf for all packages.</p>"},{"location":"package-analytics/#how-can-i-inspect-the-json-payload-that-scarf-js-sends","title":"How can I inspect the JSON payload that scarf-js sends?","text":"<p>scarf-js will run in verbose mode depending on the <code>SCARF_VERBOSE</code> environment variable:</p> <pre><code>export SCARF_VERBOSE=true\n</code></pre> <p>It will print out the JSON payload, as well as any debugging information.</p>"},{"location":"package-analytics/#i-distribute-a-package-on-npm-and-scarf-js-is-in-our-dependency-tree-can-i-disable-the-analytics-for-my-downstream-dependents","title":"I distribute a package on npm, and scarf-js is in our dependency tree. Can I disable the analytics for my downstream dependents?","text":"<p>Yes. By opting out of analytics via <code>package.json</code>, any package upstream will have analytics disabled.</p> <pre><code>// your-package/package.json\n\n{\n  // ...\n  \"scarfSettings\": {\n    \"enabled\": false\n  }\n  // ...\n}\n</code></pre> <p>Installers of your packages will have scarf-js disabled for all dependencies upstream from yours.</p>"},{"location":"package-analytics/#i-have-more-questions-where-is-the-best-place-to-ask","title":"I have more questions, where is the best place to ask","text":"<p>Join us in Slack, we're more than happy to help.</p>"},{"location":"package-analytics/#developing","title":"Developing","text":"<p>Setting the environment variable <code>SCARF_LOCAL_PORT=8080</code> will configure Scarf to use http://localhost:8080 as the analytics endpoint host.</p>"},{"location":"package-analytics/#data-collection-and-privacy","title":"Data collection and privacy","text":"<p>Scarf does not store any personally identifying information from SDK telemetry data. Scarf only collects information that is helpful for:</p> <ul> <li>Package maintenance</li> <li>Identifying which companies are using a particular package, in order to enable support agreements between developers and commercial entities.</li> </ul> <p>Specifically, scarf-js sends:</p> <ul> <li>The operating system you are using.</li> <li>Your IP address will be used to look up any available company information. Scarf does not store the actual IP address</li> <li>Limited dependency tree information. Scarf sends the name and version of the package(s) that directly depend on scarf-js. Additionally, scarf-js will send SHA256-hashed name and version for the following packages in the dependency tree:</li> <li>Packages that depend on a package that depends on scarf-js.</li> <li>The root package of the dependency tree. This allows Scarf to provide maintainers with information about which public packages are using theirs, without exposing identifying details of non-public packages.</li> </ul>"},{"location":"package-analytics/#more-languages-coming-soon","title":"More languages coming soon","text":"<p>We're working to build out sibling libraries for various languages beyond JavaScript. If you're interested in using Scarf in a language we haven't released yet, let us know!</p>"},{"location":"packages/","title":"Packages","text":""},{"location":"packages/#prerequisites","title":"Prerequisites","text":"<ul> <li>You will need to sign up for a Scarf account.     &gt; Note: You can sign up with a valid email address or your GitHub account.</li> <li>The container to be tracked must be published to a public registry; eg Docker Hub, GitHub Container Registry.</li> </ul> <p>Note: This guide will use the <code>hello-world</code> docker image.</p>"},{"location":"packages/#docker","title":"Docker","text":""},{"location":"packages/#creating-a-docker-package","title":"Creating a Docker Package","text":"<p>Using Scarf, users can pull your Docker container images via Scarf Gateway using your custom domain.</p> <ol> <li>Once signed in to Scarf, navigate to the home page.</li> <li>Click plus icon in the top navigation, then select <code>New Package</code>.     </li> <li>In the first drop-down click on the package type you would like to create. For this section you will click <code>Docker</code>.     </li> <li> <p>Enter the current pull command for your Docker container.</p> <pre><code># `hello-world` package\n\ndocker pull hello-world\n</code></pre> <p></p> </li> <li> <p>Optional: You can add a custom domain or use the domain provided by Scarf Gateway.</p> </li> <li>Click the <code>Submit</code> button to be redirected to a success screen with some additional information as to what you can do next.</li> <li>Click on on <code>Go to your package</code> to view your package details view.     </li> </ol> <p>Now you\u2019re all set to start tracking your Docker images with Scarf. Any time your image is downloaded, Scarf will report the following information:</p> <ul> <li>System and OS statistics of your users</li> <li>Company information of your users</li> <li>Downloads by versions/tags</li> </ul> <p>In the next section, you will create a tracking pixel that can be added to your project\u2019s documentation or any other web properties associated with your project.</p>"},{"location":"packages/#downloading-docker-packages","title":"Downloading Docker Packages","text":"<p>In this section you will download your package with the pull command found in your package dashboard to start fetching data.</p> <ol> <li>Navigate to your package details view.     </li> <li>Copy the Pull command.</li> <li>Navigate to a terminal on your computer and run the Pull command.      Note: Make sure the docker daemon is running on your computer.</li> <li>Back to the package details view and click on <code>View Analytics</code>. You should now see the Package Insights starting to populate with data. It will usually take 30 minutes and up to 2-3 hours before you see data pulled in. Every time a user pulls your Docker container images from Scarf Gateway the data in your Package Insights will be updated.     </li> </ol>"},{"location":"packages/#files","title":"Files","text":"<p>File Packages on Scarf are a flexible and low-level package type that can track visits and downloads on arbitrary URLs. File packages were originally created to track published tar balls, but it has since expanded to many other use cases and will likely be renamed in future versions of Scarf. You can think of File Packages as a powerful and fully customizable link shortener. Common use cases include:</p> <ul> <li>Tracking downloads of GitHub release artifacts</li> <li>Tracking downloads of every artifact on your company/project \"downloads\" page</li> <li>Tracking downloads of Homebrew packages from a tap/formula that you control</li> <li>Sending custom telemetry or other events from your application</li> <li>Tracking and attributing visits to marketing and sales content on your site.</li> </ul>"},{"location":"packages/#creating-a-file-package","title":"Creating a File Package","text":"<ol> <li> <p>Once signed in to Scarf, navigate to the home page.</p> </li> <li> <p>Click plus icon in the navigation, then select New Package. </p> </li> <li> <p>In the first drop-down click on the package type you would like to create. For this section you will click <code>File</code>. </p> </li> <li> <p>Select the package owner from the dropdown. </p> </li> <li> <p>Give your package a name. </p> </li> </ol>"},{"location":"packages/#adding-an-outgoing-and-incoming-url","title":"Adding an Outgoing and Incoming URL","text":"<p>This section explains what the Outgoing and Incoming URLs are and how to use a URL template.</p> <p>1.) Add the URL path where your files are currently located. You can add a simple URL or a URL template like in the example. <code>https://www.example.com/mypath/{version}/{platform}.tar.gz</code> This example uses 2 variables <code>{version}</code> and <code>{platform}</code>.</p> <p>Note: The Outgoing URL is the full URL to your asset on your HTTP/S hosting provider. It can be a URL template but if you use variables in your URL they need to also be used in your Incoming Path that define in the next step.</p> <p></p> <p>2.) Choose the domain where your files should be available from. You may choose to use your own domain for serving files. You may also choose to use <code>&lt;username&gt;.gateway.scarf.sh</code> provided by default by Scarf.</p> <p>3.) Add the Incoming URL Path where Scarf will direct requests to fetch a file asset.</p> <p>Note: Any variables used in your Outgoing URL path need to match your Incoming URL.</p> <p></p> <p>4.) Click Submit.</p>"},{"location":"packages/#adding-additional-routes","title":"Adding Additional Routes","text":"<p>This example will show how to add an additional route. For curl-runnings an additional route that redirects to a specific version will be added, in this case, the most recent package release.</p> <p>1.) In the top menu click on Tools then in the drop down menu click on Packages. </p> <p>2.) In the package list dashboard there will be a list of all your packages. These can be filtered by type of packages by selecting the package types you'd like to see. In our example as we just created a file package we're going to want to select File.</p> <p>3.) Navigate to our newly create file package and in the top right of the box click the <code>View Details</code> button. </p> <p>4.) In the popup modal, use the <code>File location</code> input to add a new host URL. You can use a template URL here.</p> <p>Example:</p> <p><code>https://www.example.com/mypath/latest/{platform}.tar.gz</code></p> <p>5.) Next, add the desired path format for your files. Make sure the variables from your Outgoing and Incoming URLs match if you use a template URL.</p> <p>Example:</p> <p><code>/latest/{platform}</code></p> <p></p> <p>6.) Click the <code>Submit</code> button.</p> <p>7.) The modal will close and you will see the additional route you just added.</p> <p></p>"},{"location":"packages/#whats-next","title":"What\u2019s Next?","text":"<ul> <li>Create a Pixel</li> <li>Learn more about the Scarf Gateway</li> </ul> <p>If you have questions or need help, join our Slack community.</p>"},{"location":"project-status/","title":"Project status","text":"<p>Scarf is still in its early stages and is under heavy development. Feedback of any kind of welcome. Tell us what you think! Reach out to feedback@scarf.sh or open an issue on GitHub for feature requests, bug reports, questions and comments.</p>"},{"location":"quick-start/","title":"Quick Start","text":""},{"location":"quick-start/#introduction","title":"Introduction","text":"<p>Scarf is a platform that helps you track download and usage analytics for your open source project. Scarf can collect analytics for you by:</p> <ul> <li>Tracking the downloads of your software at the point of distribution, regardless of how they are distributed (Docker containers, binaries, Python packages, npm packages, and more).</li> <li>Tracking user interactions with your web artifacts (your marketing site, your documentation, and your READMEs), without introducing cookies or JavaScript.</li> <li>Enriching any existing data you're already collecting on software usage.</li> </ul> <p>In this guide, you will learn:</p> <ul> <li>How to create track artifact downloads with Scarf -- we will use a Docker container as an example.</li> <li>How to create a tracking pixel to track views of your package's documentation</li> <li>How to test your setup by downloading your Scarf packages and fetching your associated Scarf pixels</li> </ul>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>You will need to sign up for a Scarf account.   You can sign up with a valid email address or your GitHub account.</li> <li>The container you're looking to track must be published to an existing public registry (e.g., Docker Hub or GitHub Container Registry).   This guide will use the <code>hello-world</code> docker image.</li> </ul>"},{"location":"quick-start/#creating-a-docker-package","title":"Creating a Docker Package","text":"<p>NOTE: This quickstart outlines the process for tracking downloads of a Docker container via Scarf Gateway, but you can track downloads of many other types of OSS artifacts as well. Learn more about other package types on Scarf here.</p> <p>Scarf Gateway is a service that provides a central access point to your containers and packages, no matter where you host them. Users can pull your containers via a Scarf provided domain, or custom domain that you CNAME to Scarf.</p> <ol> <li> <p>Once signed in to Scarf, navigate home by clicking on the Scarf icon in the top-left corner of the screen.</p> </li> <li> <p>Click the plus icon in the top navigation bar, then select <code>New Package</code>. </p> </li> <li> <p>In the first dropdown, click on the package type you would like to create. For this section, you will click <code>Docker</code>. </p> </li> <li> <p>Enter the current pull command for your Docker container.     The Docker command for the <code>hello-world</code> package is <code>docker pull hello-world</code>.</p> <p></p> </li> <li> <p>Optional: You can add a custom domain or use the domain provided by Scarf Gateway. If you choose to create a custom domain, you will need to CNAME your custom domain to the domain provided by Scarf Gateway.</p> </li> <li> <p>Click the <code>Submit</code> button to be redirected to a success screen with some additional information as to what you can do next.</p> </li> <li> <p>Click on <code>Go to your package</code> to view the Package Details. </p> </li> </ol> <p>Now you\u2019re all set to start tracking your Docker images with Scarf. Any time your image is downloaded, Scarf will report some basic information:</p> <ul> <li>System and OS statistics of your users</li> <li>Company information of your users</li> <li>Downloads by versions/tags</li> </ul> <p>In the next section, you will create a tracking pixel that can be added to your project\u2019s documentation or any other web properties associated with your project.</p>"},{"location":"quick-start/#creating-a-tracking-pixel-for-your-package","title":"Creating a Tracking Pixel for Your Package","text":"<p>Tracking pixels are used to leverage the web traffic from your project\u2019s documentation to learn which companies are using your software.</p> <ol> <li> <p>Navigate to the Scarf homepage.</p> </li> <li> <p>Pixels can be created from two locations, one is directly from the packages details view. In top menu click on <code>Tools</code> &gt; <code>Packages</code>. Then in the next screen find our package <code>hello-world</code> and click on <code>View details</code>.  on the next screen scroll down to the <code>Tracking Pixel</code> box and click <code>Create pixel</code>.  The second way is to click plus icon in the top navigation, then select <code>New Pixel</code>. </p> </li> <li> <p>You will now see the create pixel page. For this example we'll name our pixel <code>readme</code>.</p> </li> <li> <p>Then attach it to our the newly created <code>hello-world</code> package. (if you came to the <code>create pixel page</code> via <code>package details  page</code> this will be automatically selected) </p> </li> <li> <p>Finally click <code>Submit</code></p> </li> <li> <p>Copy the newly created pixel <code>&lt;img&gt;</code> tag and add it to your website, documentation, or any other web properties associated with your project.</p> </li> </ol> <p></p> <p>For more information on Tracking Pixels see the Documentation Insights section of our docs.</p>"},{"location":"quick-start/#downloading-packages-and-fetching-associated-pixels","title":"Downloading Packages and Fetching Associated Pixels","text":"<p>In this section you will download your package with the pull command found in your package dashboard to start fetching data.</p> <ol> <li>Navigate to your package details view.    </li> <li>Copy the Pull command.</li> <li> <p>Navigate to a terminal on your computer and run the Pull command.     Note: Make sure the docker daemon is running on your computer.</p> </li> <li> <p>Back to the package details view and click on <code>View Analytics</code>. You should now see the Package Insights starting to populate with data. It will usually take 30 minutes and up to 2-3 hours before you see data pulled in.  Every time a user pulls your Docker container images from Scarf Gateway the data in your Package Insights will be updated.</p> </li> </ol>"},{"location":"quick-start/#whats-next","title":"What\u2019s Next?","text":"<p>For more detailed information, please see the relevant documentation;</p> <ul> <li>Packages</li> <li>Scarf Gateway</li> </ul> <p>If you have questions or need help, join our Slack community.</p>"},{"location":"sales-prospecting/","title":"Scarf\u2019s Sales Prospecting Service","text":"<p>In addition to identifying open-source qualified leads (OQLs), which are the companies already engaging with your OSS, Scarf can help you operationalize that data so you can focus on growing your revenue. </p> <p>Companies familiar with your OSS are more likely to respond to sales outreach; they are truly warm leads who have already tested and are actively using your OSS.</p> <p>By identifying contacts at these companies, you can better prospect for upgrades to a paid version or a commercial support plan. </p>"},{"location":"sales-prospecting/#this-is-where-scarfs-sales-prospecting-service-comes-in","title":"This is where Scarf\u2019s Sales Prospecting Service comes in.","text":""},{"location":"sales-prospecting/#what-is-it","title":"What is it?","text":"<ul> <li>In addition to the company names provided in Scarf Basic, Scarf Premium users also get a custom report of contacts at those companies that meet your ideal customer profile (ICP) and key buyer personas.</li> </ul>"},{"location":"sales-prospecting/#who-has-access-to-it","title":"Who has access to it?","text":"<ul> <li>Customers who have purchased Scarf Premium.</li> </ul>"},{"location":"sales-prospecting/#how-does-it-work","title":"How does it work?","text":"<ul> <li>Scarf\u2019s Prospecting Service is bespoke and highly customizable. Our team pulls your list of actively engaged companies and then narrows it based on your specified ICP.</li> <li>We identify key contacts at those organizations that meet your buyer persona criteria. </li> <li>We aim to provide at least 3 contacts per company interacting with your OSS, working very closely with you to iterate on criteria together.</li> </ul>"},{"location":"sales-prospecting/#how-long-does-it-take-to-get-started","title":"How long does it take to get started?","text":"<ul> <li>There is generally a 1 week lead time to begin prospecting. </li> </ul>"},{"location":"sales-prospecting/#when-are-leads-delivered","title":"When are leads delivered?","text":"<ul> <li>Leads are delivered in a report at an agreed-upon cadence at least once weekly. </li> </ul>"},{"location":"sales-prospecting/#what-information-is-provided-with-the-contacts","title":"What information is provided with the contacts?","text":"<ul> <li>While we can accommodate some customizations to the information provided, generally, the following information is provided for each contact: <ul> <li>First &amp; Last Name</li> <li>Title</li> <li>Contact\u2019s LinkedIn Profile URL</li> <li>Contact Location (City, State, Country where available)</li> <li>Contact Phone (where available) &amp; Email</li> <li>Company Name</li> <li>Company Domain</li> <li>Activity Counts (Downloads, Telemetry, Pixel Views)</li> <li>Company HQ Country</li> <li>Company Size</li> <li>Company Industry</li> <li>Funnel Stage (Level of Engagement)</li> </ul> </li> </ul>"},{"location":"sales-prospecting/#how-do-i-use-it","title":"How do I use it?","text":"<ul> <li>Contacts discovered through Scarf Premium are OQLs for your sales development efforts.</li> <li>We recommend adding contacts to sales outreach campaigns based on the level of engagement (funnel stage). </li> <li>Contacts in early stages, such as Interest or Investigation, likely aren\u2019t ready for a meeting. Instead, we would suggest advertising (targeted to the company) on LinkedIn or other social media where you have a strong presence to create blanket awareness.<ul> <li>Invite them to follow your LinkedIn page, X (Twitter) account, or other social media accounts.</li> <li>Share your content (case studies/blog posts/podcasts, etc).</li> <li>Invite them to sign up for a newsletter.</li> </ul> </li> <li>Contacts in the Experimentation stage are good targets to invite to events such as conferences or webinars you\u2019ll be participating in or attending. </li> <li>Direct, personalized sales outreach is more appropriate for contacts in the Ongoing Usage stage, as these contacts likely have your OSS in use in production and have been actively researching and/or utilizing it for at least 90 days. </li> </ul>"},{"location":"sales-prospecting/#what-if-i-need-to-make-changes-to-my-criteria","title":"What if I need to make changes to my criteria?","text":"<ul> <li>You can change your ICP or buyer personas anytime by updating your Prospecting Service form (available under your Settings menu, Lead Generation) or by contacting your Client Success Manager. <ul> <li>Note: Depending on when they are received, changes to your criteria may take up to 5 business days to incorporate into your lead report. </li> </ul> </li> </ul>"},{"location":"sales-prospecting/#is-it-effective","title":"Is it effective?","text":"<p>To answer this question, we offer customer feedback\u2026</p> <p>\u201cOutbound outreach to Open Source Qualified Leads saw 2x higher response rates as compared to our outreach campaigns without Scarf data\u201d - Dave Donahue, Head of Global Strategy @ Unstructured.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page catalogs common issues and solutions. If you need additional help, don't hesitate to ask us in our community Slack channel.</p>"},{"location":"troubleshooting/#initial-setup","title":"Initial setup","text":""},{"location":"troubleshooting/#i-set-up-a-dockerpythonetc-package-but-my-custom-domain-doesnt-seem-to-be-working","title":"I set up a [Docker/Python/etc] package, but my custom domain doesn't seem to be working.","text":"<p>Make sure you've properly configured your CNAME to <code>gateway.scarf.sh</code>. Use the <code>dig</code> tool to inspect your <code>CNAME</code>. You should see something like:</p> <pre><code>~ \u276f\u276f\u276f dig downloads.avi.press\n; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; downloads.avi.press\n;; global options: +cmd\n;; Got answer:\n;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 45111\n;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 1232\n;; QUESTION SECTION:\n;downloads.avi.press.       IN  A\n\n;; ANSWER SECTION:\ndownloads.avi.press.    1799    IN  CNAME   avi.gateway.scarf.sh.\navi.gateway.scarf.sh.   900 IN  CNAME   a9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com.\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 54.203.228.158\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 54.186.175.150\na9568445d3bd345cea84346818c25b24-6f1f1dde0ccf3ad2.elb.us-west-2.amazonaws.com. 60 IN A 52.32.4.234\n\n;; Query time: 131 msec\n;; SERVER: 50.0.1.1#53(50.0.1.1)\n;; WHEN: Sun Dec 03 09:12:07 PST 2023\n;; MSG SIZE  rcvd: 221\n</code></pre> <p>Another factor is domain verification. On package creation you'll be prompted to verify your custom domain, if it hasn't been verified just yet.</p> <p>Use <code>dig</code> to inspect the verification TXT record. You should see something like</p> <pre><code>~ \u276f\u276f\u276f dig txt _scarf-sh-challenge-ORGANIZATION.org.example.com\n\n;; ANSWER SECTION:\n_scarf-sh-challenge-ORGANIZATION.org.example.com. 300 IN TXT \"NDVTRE6YP25CAM2PHR2B\"\n</code></pre> <p>Remember to substitute <code>ORGANIZATION</code> for your account name and <code>org.example.com</code> for your custom domain.</p>"},{"location":"troubleshooting/#my-package-is-setup-up-but-when-i-pull-im-seeing-the-error-tls-failed-to-verify-certificate-x509-certificate-is-valid-for-ingresslocal","title":"My package is setup up, but when I pull I'm seeing the error: <code>tls: failed to verify certificate: x509: certificate is valid for ingress.local</code>","text":"<p>This error means Scarf is still propagating your custom DNS setup across our datacenters globally. Typically this takes up to 30 minutes or up to 2-3 hours the first time you configure your custom domain. If you've been waiting longer and are still seeing this issue, please let us know.</p> <p>You can also see your package's domain verification status in the details overview. Expand the section for Verification to also see the CNAME and certificate status.</p>"},{"location":"troubleshooting/#my-downloads-are-working-but-im-still-not-seeing-the-data-in-my-dashboard","title":"My downloads are working but I'm still not seeing the data in my dashboard","text":"<p>Typically it takes up to 30 minutes or up to 2-3 hours for any given event to be reflected in your dashboard. We occasionally experience processing delays if our system is experiencing high volume of events, but your data isn't lost. If you're noticing unexpected delays, check our Community Slack for updates on processing delays or to report one.</p>"},{"location":"troubleshooting/#i-have-set-up-a-docker-collection-and-the-downloads-are-working-but-package-entries-are-not-being-created","title":"I have set up a Docker collection, and the downloads are working, but package entries are not being created.","text":"<p>This also sometimes takes up to 30 minutes or up to 2-3 hours, and is occasionally delayed if our system is impacted by data processing pipeline delays due to high volume. If you are still not seeing your collection be created, get in touch with us.</p>"},{"location":"troubleshooting/#i-want-to-update-a-docker-package-to-point-to-a-different-registry-but-am-getting-a-public-domains-for-docker-packages-may-only-point-to-a-single-backend-registry-at-a-time-error-how-can-i-fix-this","title":"I want to update a Docker package to point to a different registry, but am getting a <code>Public domains for Docker packages may only point to a single backend registry at a time.</code> error. How can I fix this?","text":"<p>Due to the way the OCI spec is defined, Scarf is only able to map your public domain to a single backend registry. To point to multiple registries, you need to use multiple public domains.</p>"},{"location":"troubleshooting/#how-can-i-update-the-backend-registry-for-all-of-my-containers","title":"How can I update the backend registry for all of my containers?","text":"<p>See <code>Tools</code> -&gt; <code>Packages</code> -&gt; <code>Management</code> to bulk configure your packages. If you have a Collection set up, you'll also need to update it.</p>"},{"location":"troubleshooting/#data-and-analytics","title":"Data and analytics","text":""},{"location":"troubleshooting/#i-downloaded-an-artifact-and-scarf-is-showing-my-download-as-the-wrong-company","title":"I downloaded an artifact and Scarf is showing my download as the wrong company","text":"<p>IP -&gt; Company matching is an imperfect approach and incorrect matches do happen. A few things can help understand low-confidence matches:</p> <ul> <li>You can disable \"low confidence\" companies via the toggle at the top of your company match table.</li> <li>Check the confidence for any individual event through the company activity view (click on the company) and see the \"Events\" section.</li> </ul> <p>Over time, low confidence scores are outweighed by observing company traffic in aggregate over a longer period of time rather than over-indexing on a single one-off event.</p> <p>If you're seeing persistent issues with a particular company or IP address, let us know so we can update our records accordingly and ensure high accuracy of matches.</p>"},{"location":"user_best_practices/","title":"User Guide &amp; Best Practices","text":""},{"location":"user_best_practices/#intro","title":"Intro","text":"<p>This is a user guide to best practices when using Scarf.  Consider this not only a guide but also an FAQ.  </p> <p>Currently this guide contains:</p> <ol> <li>How to use Scarf Data in existing  sales and marketing efforts<ol> <li>Events you should be tracking</li> <li>The goal is ongoing usage </li> <li>How to use Scarf to infer ongoing usage </li> <li>Basic lead scoring with Scarf</li> <li>Sample customer journey </li> <li>What to do with companies identified by Scarf</li> <li>Common ways to inject Scarf into existing sales/marketing activities </li> <li>Common ways for startups to build their first sales and marketing processes </li> </ol> </li> <li>How to use confidence intervals</li> <li>Best Practices to track multiple projects and packages<ol> <li>Handling different projects</li> <li>Handling different versions</li> <li>Handling different platforms</li> <li>Container best practices</li> <li>Variables </li> <li>Pixels for each project  </li> </ol> </li> <li>Tracking external link clicks</li> </ol>"},{"location":"user_best_practices/#how-to-use-scarf-data-in-existing-sales-and-marketing-efforts","title":"How to use Scarf data in existing sales and marketing efforts","text":""},{"location":"user_best_practices/#events-we-should-be-tracking","title":"Events we should be tracking:","text":"<p>There are 3 events we would suggest everyone track. </p> <ul> <li>Downloads/Pull events</li> <li>Views of documentation</li> <li>Views of content/website (pages, blogs, tutorials)</li> </ul> <p>The first is downloads (no matter if it's direct on your website, via a container registry, or via public repositories. Scarf allows you to track and aggregate downloads across all these different channels). This is probably the most valuable action. A download means someone has not only some interest in your product but enough interest to try it out.</p> <p>There are three aspects to downloads which you should be paying attention to:</p> <ul> <li>The number of downloads from unique sources at a company - more than one machine/source downloading is good.</li> <li>The volume of downloads over a time period at the company - you want to see continued downloads over time, this implies ongoing usage.</li> <li>Is the company downloading newer versions of the software over time - this is gold as it implies not only are they downloading but they are trying to keep things up to date and implies the software is critical enough to have maintenance procedures around it.</li> </ul> <p>The second on the list is documentation views. People using your software will often have questions about how to install, use, and upgrade the software. You will see patterns evolve over time in the usage of the software docs depending on the software. Initially you will see more traffic to the installation and setup sections. This coupled with download events is a great indicator of testing or trying things out. Then users will evolve more into troubleshooting or optimization views. See more page views shift to this is normal. Then you should see views to readmes or upgrade pages as they settle into maintenance and sustain mode. Ultimately I would be looking for views over an extended period of time to ensure they are invested and not just kicking the tires.  </p> <p>The third on the list is content/website views. Not all views will be coming from docs, in fact for commercial purposes there are certain pages on your website that may be highly predictive of potential interest in becoming a customer (i.e. the pricing pages). But I recommend looking for ongoing views and traffic hitting blogs and other news on the product and upcoming releases.  </p> <p>For each of the events, I would recommend breaking down all the activities into either good/better/best or low/medium/high impact events. </p> <p>Here is a suggested list of criteria when it comes to classifying events:</p> Event GOOD BETTER BEST Downloads 1 or more downloads in a week. More than 1 download over a 30-day period. Multiple downloads over a 90-day period, including incremental downloads of new versions. Documentation Views Repeated views on installation and setup instructions. Documentation views spanning more than 30 days from multiple sources. More than just install page views.    Documentation views spanning more than 90 days from multiple sources. Doc views on upgrades and maintenance procedures. Website Traffic Multiple pages visited and viewed by 1 company over a week period. Multiple pages visited and viewed by 1 company over a 30-day period. Page views to medium value content. I.e. Reading technical blogs, visiting forum pages, product feature pages."},{"location":"user_best_practices/#the-riskiest-but-most-valuable-metric-ongoing-usage","title":"The Riskiest But Most Valuable Metric: Ongoing Usage","text":"<p>While the three activities above are straightforward and generally not viewed with too much concern, there is a fourth activity or metric you can (and probably should) track.  An essential, albeit controversial, activity that serves as a highly valuable metric for any organization seeking to understand the usage patterns of its software - the use of 'call-home' functionality, also known as ongoing usage tracking. The call-home functionality is a mechanism within your software that sends a signal, or a 'ping', back to a designated server or gateway. This signal provides you with real-time information about your software's usage in live production environments, surpassing the insight level gained from just tracking downloads.</p> <p>While download data can indicate interest and repeated use of your software, the ongoing, consistent 'ping' or call-home activity serves as a definitive predictor of your software's actual usage. Consider this the 'Nirvana' of metrics for your projects, the golden standard that allows you to measure the exact magnitude of your active install base and the frequency of software usage and deployment.</p> <p>However, implementing this mechanism requires a degree of technical adaptation. Platforms like Scarf, for instance, offer this capability out of the box. But to make full use of it, you'll need to adjust your application accordingly. There are different ways to accomplish this; for JavaScript applications, a package called <code>scarf-js</code> can be used. Alternatively, a lightweight, background 'ping' or activity back to a Scarf gateway event can be employed. This ping can be triggered when your application starts up, is used, or at any other specified event.</p> <p>In essence, your application would asynchronously call back to the gateway website, which doesn't return any data but rather tracks that the application was active. If you can successfully implement this, you can then monitor the number of unique pings over a certain period from various sources. This is incredibly valuable for lead scoring as it provides consistent, ongoing proof of life from these systems, making it the most valuable event or activity you could track.</p>"},{"location":"user_best_practices/#how-to-use-scarf-to-infer-ongoing-usage","title":"How to use Scarf to infer ongoing usage","text":"<ul> <li>Look for companies activities over an extended period of time. Repeated downloads over 30/90/180 days is a very predictive indicator of ongoing reliance </li> <li>Look for companies who download incremental versions of your software over time</li> <li>Look at documentation views over time, especially upgrade docs and operational docs from the same user/company</li> <li>Consider adding a ping or call back within your software to an empty page behind a Scarf Gateway URL, this will allow you see these calls within Scarf.  </li> </ul>"},{"location":"user_best_practices/#basic-lead-scoring-and-customer-journey-mapping-with-scarf","title":"Basic lead scoring and customer journey mapping with Scarf","text":"<p>Not all people visiting your website and downloading your software are equally likely to become customers. In fact you will find 3x, 5x, or even 10x more drive by traffic as you will find those interested in commercial offerings. To become efficient at finding which companies and users you should focus on, let's explore the concept of \u201clead scoring\u201d. </p> <p>Lead scoring is a methodology used by sales and marketing departments to determine the worthiness of leads, or potential customers, by assigning values to them based on their behavior relating to their interest level in products or services. These values, or scores, are derived from a variety of factors like the professional information they've submitted, how they've engaged with the company's website, or their response to marketing efforts. The purpose of lead scoring is to prioritize leads who are more likely to convert into customers, allowing teams to focus their time and resources effectively. It's a vital part of creating an efficient sales and marketing strategy.</p> <p>If you've already established a lead scoring system and are utilizing marketing software, consider events in open-source channels as additional data points to further qualify or uncover leads. For instance, a software download could be treated as a high-value (or high-score) activity, whereas a documentation view might be scored similarly to other website visits. It could be beneficial to categorize documentation and page views into high, medium, and low scoring pages, as certain pages (like pricing or install pages) can be more predictive and valuable than others.</p> <p>The key distinction between traditional lead scoring and the incorporation of open-source download and traffic data lies in the summarization of data at the company level, requiring decisions on scoring criteria. Most marketing lead management tools track users based on sign-ups, cookies, or other mechanisms, capturing specifics such as Matt from Scarf signing up for a webinar. With data from anonymous sources, the best we can do is infer that someone from Scarf has downloaded your software.</p> <p>The question then becomes: if you know Matt attended a webinar and works at Scarf, does the Scarf download make Matt a more qualified lead? Or should you shift your focus to other individuals at Scarf, possibly higher up in the management hierarchy? There's no absolute right or wrong answer, but my inclination would be to enrich the data of the known user who has already shown interest.</p> <p>Additionally, it's important to note that software downloads can often be automated. Seeing ten downloads a day doesn't necessarily equate to thousands of servers or the potential for a massive deal. This data needs to be scrutinized, at the very least, by examining the unique systems or origins from where these downloads originate.</p> <p>Lastly, when incorporating open-source downloads and traffic data, the timeline of events becomes critical. A single download could mean anything, but consistent downloads over several months, especially with each new version release, suggests a real, potentially highly qualified user.</p>"},{"location":"user_best_practices/#customer-journey-example-with-scarf","title":"Customer journey example with Scarf","text":"Different Phases of Interest Description Events Action Passive interest: Hello World Someone discovered or visited your website. They may or may not have any interest in your software or projects. Web traffic to docs or websites over the course of 1 or 2 days. I would not take any action here. Intrigued in your software: This looks interesting Someone takes more than a drive by interest in your software.  They are truly interested in what you have. Documentation views. Looking at install docs and/or feature lists. Typically this is over multiple days. I would consider promoting content tothat company's target audience (engineers?) on other external channels. Trial &amp; Exploration: Let me try this out They move from just learning about the software to actually downloading it. Documentation and website views of high value pages along with at least 1 download event.You still see this traffic over multiple days but typically over a week or two. I would recommend promoting blogs or how-tos that are interesting to this group of customers. You could even promote this content directly on your website when these visitors appear. Testing &amp; Evaluation: I wonder if I can usethis for this project Now someone is looking deeper into this and is starting to either use it or seriously consider it. Sustained page views and multiple downloads over a month period. Here is where additional content promotion is still a good idea, but where there is a strong commercial offering targeting these customers can be effective. Implementation &amp; Reliance: This is cool, let's use this in production Someone is using this over a longer period of time and looks to be beyond merely testing/trying out. If you see activities (both downloads and traffic) spread over a 90 day period, there is a high confidence in their usage in a critical space. This is the best time to seek out conversations. - Cold outreach - Targeted ads - Seek out devs at conferences Maintenance &amp; Ongoing Upkeep: Keeping things updated and safe Someone has been using your software for months and is grabbing new versions of your software and reading readmes or regular updates (like blogs). Look for activities over months (3-12 months), with downloads of multiple versions. Also look for views on readmes or product specific content (blogs, etc). This is the best time to seek out conversations. - Cold outreach - Targeted ads - Seek out devs at conferences Waning Interest &amp; Potential Churn: Uh oh\u2026 this user is at risk Usage is dropping and there is risk that this user may turn from an active user to a former user. If you see massive drop offs in traffic and downloads over a 30 day period this sends up red flags."},{"location":"user_best_practices/#what-to-do-with-companies-identified-by-scarf","title":"What to do with companies identified by Scarf","text":"<p>Effectively employing this data requires a strategic and tailored approach to meet the unique needs and goals of each organization. Below are some general recommendations that apply to most situations:</p> <ul> <li>Understand Your Audience: Use download data and website traffic information to build a deeper understanding of your audience. This involves analyzing who is downloading your software, viewing your documentation, and browsing your website. With this information, you can enrich your existing leads, score potential ones, and build a well-informed customer profile.</li> <li>Customize Your Approach: Once you've gathered and analyzed your data, tailor your marketing and sales processes to align with your findings. Whether you're focusing on sales/marketing or product, align your strategies and activities with the preferences and behaviors of your users. This could involve adjusting lead scoring based on the activity level or nurturing potential users to become ongoing ones.</li> <li>Integrate Data with Existing Processes: Integrate your new data with your existing sales, marketing, and customer success processes. For instance, using download patterns to assess the churn potential can help you anticipate and mitigate customer attrition.</li> <li>Adopt a Nurturing Approach: When it comes to new or startup sales/marketing processes, take a nurturing approach. This means guiding users through a lifecycle where they are initially familiarized with your software, then nurtured to become regular users, and eventually led to become paid customers.</li> <li>Leverage Social Media: Social media platforms offer targeted marketing opportunities. Platforms like LinkedIn allow you to aim your promoted content towards specific companies and job titles.</li> <li>Optimize Content: Make use of your existing content and create new content based on where your users and companies are spending the most time. Calls-to-action (CTAs) on these pages can effectively guide users through your marketing funnel.</li> <li>Community Engagement: Encourage users to join your community, participate in events, and engage in discussions. Community engagement can serve as a powerful tool for user retention and organic growth.</li> <li>Monitor and Adapt: Regularly assess the effectiveness of your strategies and be willing to make necessary adjustments. The digital landscape is ever-evolving, and your strategies should be adaptable to accommodate these changes.</li> </ul>"},{"location":"user_best_practices/#common-ways-to-inject-scarf-into-salesmarketing-activities","title":"Common ways to inject Scarf into sales/marketing activities:","text":"<p>Existing sales and marketing activities can be significantly enriched by smartly integrating download data and website traffic information. By revising your lead scoring methodology to include new data points such as software downloads and page visits, you can ensure that you are incorporating the latest indicators of interest from your audience. The enhanced lead scoring will provide a more nuanced understanding of your prospective customers, paving the way for more targeted and effective outreach.</p> <p>Use the company lists generated from this data in your cold outreach activities. By focusing your outreach efforts on these companies, you are targeting organizations already demonstrating interest, thereby increasing your chances of gaining a receptive audience. These lists can also serve as a valuable resource for your Business Development Representatives (BDRs), equipping them with a list of vetted leads, saving time and improving their efficiency.</p> <p>Additionally, using this data, you can strategically plan meetings at conferences, events, and similar networking platforms with representatives from companies using or showing interest in your product. This targeted networking can lead to higher-value interactions and ultimately result in stronger leads.</p> <p>Incorporating the pattern of downloads into your customer success and renewal operations can provide a more comprehensive customer overview. Such insights into customer behavior can inform your renewal strategies, equipping you with necessary foresight to address potential issues and ensure customer satisfaction. Moreover, the data can be a key indicator of potential churn risks, allowing you to proactively manage customer retention by identifying and addressing their concerns before they choose to discontinue your service.</p> <ul> <li>Use the data to enrich your existing set of leads. You can add additional events to your lead scoring process.</li> <li>Use the data to build a highly qualified list for outreach activities. Target companies that are using your software or are interested in your software.</li> <li>Use this data to inform your marketing strategies. For example, prioritize individuals from companies that have shown interest in your software at meetings, conferences, and events.</li> <li>If you have a fully fleshed out sales, marketing, and customer success process, use the data to assess churn risk.</li> </ul>"},{"location":"user_best_practices/#common-ways-for-startups-to-build-their-first-salesmarketing-process-with-scarf","title":"Common ways for startups to build their first sales/marketing process with Scarf:","text":"<p>For startups or companies initiating new sales and marketing initiatives, creating a lightweight growth engine that nurtures potential users can be the key to driving growth. Setting up a lifecycle or nurture campaign can guide potential users through your marketing funnel, providing them with the right content at the right time to foster interest and engagement.</p> <p>Promoted content can be a powerful tool in these campaigns. Aimed at users in the early stages of engagement, this content can educate users about your software, showcasing its features and benefits and encouraging them to explore it further. As these potential users turn into ongoing users, you can begin to introduce promoted content, offers, and cold outreach to convert them into paying customers.</p> <p>Understanding the customer journey is crucial in a startup or new marketing environment. By mapping out this journey and identifying combinations of events and thresholds, you can strategize when to increase or decrease marketing activities for optimal effect. This dynamic approach can keep your marketing efforts agile and responsive to user behavior.</p> <p>Social media platforms like LinkedIn offer a targeted way to reach specific companies.</p> <ul> <li>Use this data to build a lightweight marketing and growth engine.</li> <li>Approach the process as a life cycle or nurture-type campaign. Nurture potential users until they become productive users.</li> <li>Use promoted content targeted towards companies that are downloading or have looked at your documentation.</li> <li>Once users are actively using your software, shift the focus to ongoing maintenance and new releases. Then, start introducing your paid offerings or services.</li> <li>Use social media to engage potential users, specifically for companies you identified</li> <li>Integrate the scarf platform into your existing community activity to help nurture and guide potential users.</li> </ul>"},{"location":"user_best_practices/#how-to-use-confidence-intervals","title":"How to use confidence intervals","text":"<p>In your Scarf dashboards you will often see a confidence flag associated with events and companies.</p> <p></p> <p>The confidence is a measurement of Scarf's confidence in the IP/metadata -&gt; organization match for each event. Some of our metadata providers like Clearbit provide their own confidence scores and Scarf will take those into account, but we also account for what other providers say. We will make our own adjustments in many cases, for instance, if there is disagreement between the different data providers we use, or if we find irregularities in the metadata.</p> <p>Confidence intervals have 2 data points associated with them. The first is the overall flag which is low (red), medium (yellow), and high (green) confidence. This gives you a quick way to associate high-probability matches with low ones. When looking into the flags, you will find a percent (%) of confidence associated with each company and event, and these percentages can be used to differentiate further which companies and events to prioritize.</p> Confidence Description How to Use Low Low confidence matches, based on available data we suspect these events are associated with this company, but can not be 100% sure. We do not recommend taking direct action on small numbers of low confidence matches.  Consider these to be very low quality leads, if leads at all. This data however is valuable if correlated with outside data for this organization.  For instance if you know this organization is active in the community or if you see multiple low confidence leads over the course of weeks or months from unique end points, this may indicate these are higher quality then our data suggests. Medium These events have an above average chance of being from associated companies.  We have been able to match multiple checks in the metadata and our external providers have an above average confidence in their match. Medium confidence matches should be considered second tier data, with leads being followed up after processing higher condfidence data. This data is valuable in enriching other data source and we would feel confident in using it for trends, analysis, and as part of a broader customer intelligence effort. In part of an ABM (account based marketing) strategy we would feel confident in using these matches correlated with a list of targeted accounts. This is also a good list of organizations for BDR and prospecting activities. High The events and organizations that have a high confidence interval mean that we have multiple high probability indicators of a match to an organization for these events. High confidence matches provide the highest quality data. We are confident in people using this data for their sales pipelines, lead scoring, etc. These records could be integrated into exsiting tools to give a complete picture of a customers journey <p></p>"},{"location":"user_best_practices/#best-practices-to-track-multiple-packages-or-projects","title":"Best practices to track multiple packages or projects","text":"<p>Many of our customers offer downloads of multiple different open source projects, different versions, or downloads for different platforms. There are some best practices we have found useful for many of our customers when faced with dozens or even hundreds of unique packages. Your decisions on how to handle multiple packages, projects, or versions ultimately will come down to a.) how you want to report the data and b.) personal preference. </p> <p>Keep in mind you can export data and report on a variety of metrics by package, variable, etc. However, if you want to get quick analytics using the Scarf dashboards, reporting is done for all your packages (global), an individual package, or a specific pixel. You can see metrics for each variable under a package or pixel. As of July 2023, variable reporting on a package or pixel is limited to a single dimension. i.e.  I can see a report for <code>{variable1}</code> or <code>{variable2}</code> for a package or pixel, but I can not see data for <code>{variable1}</code> correlated with <code>{variable2}</code>. You can, of course, do this correlation and analysis by exporting and using your own analytics tool. Keep this in mind as you build your packages and routes.  </p>"},{"location":"user_best_practices/#handling-different-projects","title":"Handling different projects","text":"<p>You may have different open-source projects you support and ship to the community. For these we recommend setting up a new package for each project.</p>"},{"location":"user_best_practices/#handling-different-versions","title":"Handling different versions","text":"<p>In the gateway, we recommend setting up a minimum of 1 package per project. Each package created within Scarf should have 1 or more routes. i.e., <code>http://companyname.gateway.scarf.sh/projectname/file.gz</code> would be the minimum. We recommend using variables for each version you are currently supporting, i.e., <code>http://companyname.gateway.scarf.sh/projectname/{version}/file.gz</code> or <code>http://companyname.gateway.scarf.sh/projectname/file.{version}.gz</code> this allows you to update and release versions without having to create new routes for each. This also enables reporting in the Scarf dashboard to track downloads and growth of each version.  </p> <p>Some people have found it easier to create routes for new major versions, but you could also use multiple variables for this. I.e.</p> <ul> <li><code>http://companyname.gateway.scarf.sh/projectname/V1/file.{minorversion}.gz</code></li> <li><code>http://companyname.gateway.scarf.sh/projectname/V2/file.{minorversion}.gz</code></li> <li><code>http://companyname.gateway.scarf.sh/projectname/{majorversion}/file.{minorversion}.gz</code></li> </ul> <p>Depending on your needs, you could create a new package for each major version, but it is not required.</p>"},{"location":"user_best_practices/#handling-different-platforms","title":"Handling different platforms","text":"<p>Similar to handling different versions, you can use variables if you are shipping different package types or for different platforms. So instead of:</p> <p><code>http://companyname.gateway.scarf.sh/projectname/RHEL5/{majorversion}/file.{minorversion}.gz</code> and  <code>http://companyname.gateway.scarf.sh/projectname/RHEL6/{majorversion}/file.{minorversion}.gz</code></p> <p>You could do the following:</p> <p><code>http://companyname.gateway.scarf.sh/projectname/{osversion}/{majorversion}/file.{minorversion}.gz</code></p>"},{"location":"user_best_practices/#containers","title":"Containers","text":"<p>For containers, we recommend setting up a \"Collection\" to sit in front of your entire namespace, i.e., <code>company/*</code> on Docker Hub or your preferred container registry. Collections automatically sync and keep up to date with container registries making it easy to release new versions without having to worry about Scarf being up to date with new releases. To learn more, check out the collections docs</p> <p>You can use variables just like you do for other downloads. </p>"},{"location":"user_best_practices/#variable-order","title":"Variable order","text":"<p>No matter what kind of package you are using, we recommend ensuring your different file packages have distinct, concrete prefixes in their route to prevent ambiguous overlap in redirect config. For instance: </p> <p><code>http://companyname.gateway.scarf.sh/{os}/{os_version}/packagename/{filename}</code> </p> <p>Technically would work, but this will limit reporting and cause overlapping issues. As a result, we would recommend hardcoding routes to the attributes you want to report on first in your route, with variables stored towards the back of the route. So, for instance : </p> <p><code>http://companyname.gateway.scarf.sh/packagename/{os}/{os_version}/{filename}</code>. </p> <p>Doing so will allow you to report on each package name separately, with slices broken out by each variable as needed.  </p>"},{"location":"user_best_practices/#unique-pixels-for-each-projects-docs","title":"Unique pixels for each projects docs","text":"<p>While optional, it can be a good idea to make unique pixels specific to docs pages pertaining to the package to easily correlate web/docs traffic pertaining to certain packages. Ultimately this is more of a convenience when it comes to analyzing the data, but it's not at all necessary.</p> <p>Depending on your needs, here are two strategies you may find useful:</p>"},{"location":"user_best_practices/#pixels-for-lead-gen","title":"Pixels for lead gen","text":"<p>If you have different types of content, some content or pages may, in fact, be more valuable for users than others. In this case, one strategy may be to create multiple pixels for different types of pages. Consider this:</p> <p>Create 4 pixels:</p> <ul> <li>General traffic<ul> <li>Embed the general traffic pixel on all pages.  </li> </ul> </li> <li>high value <ul> <li>Embed the high value on your pricing pages, support pages, and other highly desirable docs/website pages.  </li> </ul> </li> <li>medium value<ul> <li>Embed the medium value pixel on your installation and setup docs, tutorials, or other mid-level docs. </li> </ul> </li> <li>low value<ul> <li>Embed the low-value pixel on everything else.  </li> </ul> </li> </ul> <p>Now you will be able to classify and score users' activities based on what sort of content they viewed. You can even bake this into your existing lead-scoring system.  </p>"},{"location":"user_best_practices/#overlapping-pixels-for-tags","title":"Overlapping pixels for tags","text":"<p>You can embed multiple pixels on the same page for different reasons to facilitate more detailed reporting. For instance, you may want to create one pixel for each project, but you may also want to create a pixel for just specific types of content on your website or elsewhere on the web. For instance, maybe you want everyone looking at blogs or tutorials on a critical feature to be tracked and have metrics reported on.  </p>"},{"location":"user_best_practices/#tracking-external-link-clicks","title":"Tracking external link clicks","text":"<p>A gateway route does not have to link back to a file to download; it can also forward traffic to a URL and track the traffic who clicked the link. This allows you to track who is clicking on links in social media, watching videos, clicking on links in external content, etc. We created a tutorial on this here:</p>"},{"location":"web-traffic/","title":"Documentation Insights","text":"<p>Scarf can help you understand how people and companies discover and learn about your project by surfacing insights based on the web traffic to your project's documentation pages, READMEs, and other web properties. Scarf offers lightweight, cookie-free analytics pixels that work anywhere on the internet your content is read. Unlike traditional JavaScript-based web analytics, image-based telemetry works in places where JavaScript execution is not accessible. Not using cookies means no annoying cookie banners are needed, and your readers are never tracked as they continue to surf the web. </p> <p>If you observe readers from a particular company frequently viewing your project documentation, this can indicate an opportunity for landing support contracts or sponsorship to financially support your project. Seeing repeat visitors to certain pages in your docs may hint at parts of your project that are confusing or can be clarified. </p> <p>Pairing Documentation Insights with Scarf's package analytics can help you better understand your OSS-user-journey, and your associated conversion rates. Given that someone sees your landing page, what's the likelihood they continue on to download your latest binary, container image, or other artifact?</p>"},{"location":"web-traffic/#features","title":"Features","text":"<p>Scarf's project Documentation Insights offers insights into:</p> <ul> <li>Which businesses are looking at your project's documentation.</li> <li>Aggregated location information associated with this web traffic.</li> <li>Which parts of your documentation are looked at most.</li> <li>With tooling that works in READMEs (or rendered docs generally), emails, and other places on the web where JavaScript is not typically executed.</li> <li>Conversion rates from viewing docs to downloading your artifacts</li> </ul>"},{"location":"web-traffic/#how-it-works","title":"How it works","text":"<p>Scarf gathers web traffic insights via a simple transparent tracking pixel. You copy an <code>&lt;img&gt;</code> tag from Scarf into your project's README, docs, or any other web property, and any time a user loads the image from us, Scarf will look up any business metadata associated with the address and surface that information to you (and only you) via your free Scarf account. Scarf does not store the IP address itself, so no personally identifiable information is collected.</p>"},{"location":"web-traffic/#creating-a-pixel","title":"Creating a pixel","text":"<p>Head to your Scarf dashboard and click the <code>+</code> in the top-right corner, then click <code>New Pixel</code>. Give your pixel(s) a name, select an Owner to manage its scope (your organization recommended), and optionally attach it to a package you manage on Scarf. This package attachment is optional and is solely used for visualizing the statistics for a pixel and a package together on the same page within the Scarf dashboard UI. </p>"},{"location":"web-traffic/#embedding-and-using-the-pixel","title":"Embedding and using the pixel","text":"<p>Head to your Scarf dashboard and, in the <code>Tools</code> dropdown, select <code>Pixels</code>. Click <code>Copy Pixel Snippet</code> to copy the <code>&lt;img&gt;</code> tag to your clipboard, and then paste the tag into your project's README, docs, and any other web properties where you want to gather insights into who is using your documentation pages.</p>"},{"location":"web-traffic/#caveats","title":"Caveats","text":""},{"location":"web-traffic/#data-precision","title":"Data Precision","text":"<p>View counts from Documentation Insights data should be considered as approximate and not exact. Page loads are a noisy signal, and Scarf's infrastructure that serves your tracking pixel is optimized to always load quickly and never get in the way, rather than having an exact page load count.</p>"},{"location":"web-traffic/#sources","title":"Sources","text":"<p>Pixel-based telemetry will work on standard webpages, rendered markdown documentation on package registry sites like <code>Docker Hub</code>, <code>npm</code>, and <code>PyPi</code>, and anywhere an image can be embedded, with a notable exception being GitHub. When GitHub renders markdown, it rewrites URLs from their original web address to https://camo.githubusercontent.com/, where GitHub hosts any linked images themselves. This prevents Scarf from providing insights to maintainers, since all that can now be detected at the original web address via the tracking pixel is undifferentiated traffic from GitHub."}]}